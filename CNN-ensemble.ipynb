{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae1d93fa-5d50-420f-8c75-3dc3b06f67c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b25b804-29a8-48e6-abe5-c9b15a579fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "def train_and_validate(model, train_loader, test_loader, epochs=20):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_outputs = []\n",
    "        train_labels = []\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "            train_outputs.extend(outputs.detach().cpu().numpy())\n",
    "            train_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        train_loss = np.mean(train_losses)\n",
    "        train_preds = np.argmax(train_outputs, axis=1)\n",
    "        train_acc = accuracy_score(train_labels, train_preds)\n",
    "        train_f1 = f1_score(train_labels, train_preds, average='micro')\n",
    "        train_prec = precision_score(train_labels, train_preds, average='micro')\n",
    "        train_recall = recall_score(train_labels, train_preds, average='micro')\n",
    "\n",
    "        # Validation part\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        val_outputs = []\n",
    "        val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_losses.append(loss.item())\n",
    "                val_outputs.extend(outputs.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss = np.mean(val_losses)\n",
    "        val_preds = np.argmax(val_outputs, axis=1)\n",
    "        val_acc = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='micro')\n",
    "        val_prec = precision_score(val_labels, val_preds, average='micro')\n",
    "        val_recall = recall_score(val_labels, val_preds, average='micro')\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}, Train Prec: {train_prec:.4f}, Train Recall: {train_recall:.4f}')\n",
    "        print(f'Epoch {epoch + 1}/{epochs} - Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}, Val Prec: {val_prec:.4f}, Val Recall: {val_recall:.4f}')\n",
    "        print()\n",
    "        # print(f'Epoch {epoch + 1}/{epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "        #print(f'Epoch {epoch + 1}/{epochs} - Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "        # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f9b7e1c-66af-4559-bd29-7922a859d172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X = np.load(\"scRNA_full.npy\")\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "# Open labels and process\n",
    "with open(\"label.txt\") as f:\n",
    "    labels = [line.strip() for line in f.readlines()]\n",
    "label_to_index = {label: i for i, label in enumerate(np.unique(labels))}\n",
    "y = torch.tensor([label_to_index[label] for label in labels], dtype=torch.long)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19840ed0-b373-4faf-8226-72c905667d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7022, 13822])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cd724f0-bd7c-44fe-8120-8884fc2dc8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelEnsemble(\n",
      "  (models): ModuleList(\n",
      "    (0): PyTorchModel(\n",
      "      (conv1): Conv1d(1, 64, kernel_size=(7,), stride=(4,), padding=(3,))\n",
      "      (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "      (conv2): Conv1d(64, 128, kernel_size=(5,), stride=(2,), padding=(2,))\n",
      "      (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "      (fc1): Linear(in_features=13824, out_features=512, bias=True)\n",
      "      (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (output_layer): Linear(in_features=256, out_features=14, bias=True)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (batch_norm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (batch_norm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): PyTorchModel(\n",
      "      (conv1): Conv1d(1, 64, kernel_size=(7,), stride=(4,), padding=(3,))\n",
      "      (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "      (conv2): Conv1d(64, 128, kernel_size=(5,), stride=(2,), padding=(2,))\n",
      "      (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "      (fc1): Linear(in_features=13824, out_features=512, bias=True)\n",
      "      (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (output_layer): Linear(in_features=256, out_features=14, bias=True)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (batch_norm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (batch_norm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): PyTorchModel(\n",
      "      (conv1): Conv1d(1, 64, kernel_size=(7,), stride=(4,), padding=(3,))\n",
      "      (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "      (conv2): Conv1d(64, 128, kernel_size=(5,), stride=(2,), padding=(2,))\n",
      "      (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "      (fc1): Linear(in_features=13824, out_features=512, bias=True)\n",
      "      (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (output_layer): Linear(in_features=256, out_features=14, bias=True)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (batch_norm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (batch_norm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): PyTorchModel(\n",
      "      (conv1): Conv1d(1, 64, kernel_size=(7,), stride=(4,), padding=(3,))\n",
      "      (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "      (conv2): Conv1d(64, 128, kernel_size=(5,), stride=(2,), padding=(2,))\n",
      "      (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "      (fc1): Linear(in_features=13824, out_features=512, bias=True)\n",
      "      (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (output_layer): Linear(in_features=256, out_features=14, bias=True)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (batch_norm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (batch_norm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): PyTorchModel(\n",
      "      (conv1): Conv1d(1, 64, kernel_size=(7,), stride=(4,), padding=(3,))\n",
      "      (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "      (conv2): Conv1d(64, 128, kernel_size=(5,), stride=(2,), padding=(2,))\n",
      "      (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "      (fc1): Linear(in_features=13824, out_features=512, bias=True)\n",
      "      (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (output_layer): Linear(in_features=256, out_features=14, bias=True)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (batch_norm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (batch_norm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class PyTorchModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PyTorchModel, self).__init__()\n",
    "        # First 1D convolutional layer\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=7, stride=4, padding=3)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        \n",
    "        # Second 1D convolutional layer\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5, stride=2, padding=2)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        \n",
    "        # Calculate the output size after the convolution and pooling layers\n",
    "        self.conv1_output_size = (13822 + 2 * 3 - 7) // 4 + 1  # padding=3, kernel_size=7, stride=4\n",
    "        self.pool1_output_size = self.conv1_output_size // 4  # pool_size=4, stride=4\n",
    "\n",
    "        self.conv2_output_size = (self.pool1_output_size + 2 * 2 - 5) // 2 + 1  # padding=2, kernel_size=5, stride=2\n",
    "        self.pool2_output_size = self.conv2_output_size // 4  # pool_size=4, stride=4\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * self.pool2_output_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.output_layer = nn.Linear(256, 14)\n",
    "        \n",
    "        # Regularization layers\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(512)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add channel dimension\n",
    "        x = x.unsqueeze(1)  # Shape (batch_size, 1, 13822)\n",
    "        \n",
    "        # Convolutional layers\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers with dropout and batch normalization\n",
    "        x = self.dropout(F.relu(self.batch_norm1(self.fc1(x))))\n",
    "        x = self.dropout(F.relu(self.batch_norm2(self.fc2(x))))\n",
    "        \n",
    "        # Output layer\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "class ModelEnsemble(nn.Module):\n",
    "    def __init__(self, n_models, base_model):\n",
    "        super(ModelEnsemble, self).__init__()\n",
    "        self.models = nn.ModuleList([base_model() for _ in range(n_models)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        outputs = [model(x) for model in self.models]\n",
    "        # Average the outputs from different models\n",
    "        avg_output = torch.mean(torch.stack(outputs), dim=0)\n",
    "        return avg_output\n",
    "\n",
    "# Instantiate the ensemble with a number of models\n",
    "n_models = 5\n",
    "ensemble_model = ModelEnsemble(n_models, PyTorchModel)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = optim.Adam(ensemble_model.parameters(), lr=0.0005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Model summary-like printout\n",
    "print(ensemble_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c781ebf6-2b64-440a-8cef-ec188685cd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000 - Train Loss: 2.4278, Train Acc: 0.2726, Train F1: 0.2726, Train Prec: 0.2726, Train Recall: 0.2726\n",
      "Epoch 1/1000 - Val Loss: 2.1872, Val Acc: 0.5047, Val F1: 0.5047, Val Prec: 0.5047, Val Recall: 0.5047\n",
      "\n",
      "Epoch 2/1000 - Train Loss: 2.0620, Train Acc: 0.4534, Train F1: 0.4534, Train Prec: 0.4534, Train Recall: 0.4534\n",
      "Epoch 2/1000 - Val Loss: 1.9358, Val Acc: 0.5970, Val F1: 0.5970, Val Prec: 0.5970, Val Recall: 0.5970\n",
      "\n",
      "Epoch 3/1000 - Train Loss: 1.8503, Train Acc: 0.5212, Train F1: 0.5212, Train Prec: 0.5212, Train Recall: 0.5212\n",
      "Epoch 3/1000 - Val Loss: 1.7761, Val Acc: 0.6429, Val F1: 0.6429, Val Prec: 0.6429, Val Recall: 0.6429\n",
      "\n",
      "Epoch 4/1000 - Train Loss: 1.7037, Train Acc: 0.5738, Train F1: 0.5738, Train Prec: 0.5738, Train Recall: 0.5738\n",
      "Epoch 4/1000 - Val Loss: 1.6504, Val Acc: 0.6731, Val F1: 0.6731, Val Prec: 0.6731, Val Recall: 0.6731\n",
      "\n",
      "Epoch 5/1000 - Train Loss: 1.5929, Train Acc: 0.6072, Train F1: 0.6072, Train Prec: 0.6072, Train Recall: 0.6072\n",
      "Epoch 5/1000 - Val Loss: 1.5321, Val Acc: 0.6993, Val F1: 0.6993, Val Prec: 0.6993, Val Recall: 0.6993\n",
      "\n",
      "Epoch 6/1000 - Train Loss: 1.4946, Train Acc: 0.6426, Train F1: 0.6426, Train Prec: 0.6426, Train Recall: 0.6426\n",
      "Epoch 6/1000 - Val Loss: 1.4548, Val Acc: 0.7136, Val F1: 0.7136, Val Prec: 0.7136, Val Recall: 0.7136\n",
      "\n",
      "Epoch 7/1000 - Train Loss: 1.4112, Train Acc: 0.6638, Train F1: 0.6638, Train Prec: 0.6638, Train Recall: 0.6638\n",
      "Epoch 7/1000 - Val Loss: 1.3840, Val Acc: 0.7342, Val F1: 0.7342, Val Prec: 0.7342, Val Recall: 0.7342\n",
      "\n",
      "Epoch 8/1000 - Train Loss: 1.3302, Train Acc: 0.6863, Train F1: 0.6863, Train Prec: 0.6863, Train Recall: 0.6863\n",
      "Epoch 8/1000 - Val Loss: 1.3121, Val Acc: 0.7445, Val F1: 0.7445, Val Prec: 0.7445, Val Recall: 0.7445\n",
      "\n",
      "Epoch 9/1000 - Train Loss: 1.2721, Train Acc: 0.7125, Train F1: 0.7125, Train Prec: 0.7125, Train Recall: 0.7125\n",
      "Epoch 9/1000 - Val Loss: 1.2390, Val Acc: 0.7558, Val F1: 0.7558, Val Prec: 0.7558, Val Recall: 0.7558\n",
      "\n",
      "Epoch 10/1000 - Train Loss: 1.2097, Train Acc: 0.7308, Train F1: 0.7308, Train Prec: 0.7308, Train Recall: 0.7308\n",
      "Epoch 10/1000 - Val Loss: 1.1985, Val Acc: 0.7774, Val F1: 0.7774, Val Prec: 0.7774, Val Recall: 0.7774\n",
      "\n",
      "Epoch 11/1000 - Train Loss: 1.1577, Train Acc: 0.7521, Train F1: 0.7521, Train Prec: 0.7521, Train Recall: 0.7521\n",
      "Epoch 11/1000 - Val Loss: 1.1342, Val Acc: 0.7794, Val F1: 0.7794, Val Prec: 0.7794, Val Recall: 0.7794\n",
      "\n",
      "Epoch 12/1000 - Train Loss: 1.1066, Train Acc: 0.7570, Train F1: 0.7570, Train Prec: 0.7570, Train Recall: 0.7570\n",
      "Epoch 12/1000 - Val Loss: 1.0908, Val Acc: 0.7887, Val F1: 0.7887, Val Prec: 0.7887, Val Recall: 0.7887\n",
      "\n",
      "Epoch 13/1000 - Train Loss: 1.0691, Train Acc: 0.7693, Train F1: 0.7693, Train Prec: 0.7693, Train Recall: 0.7693\n",
      "Epoch 13/1000 - Val Loss: 1.0466, Val Acc: 0.7924, Val F1: 0.7924, Val Prec: 0.7924, Val Recall: 0.7924\n",
      "\n",
      "Epoch 14/1000 - Train Loss: 1.0238, Train Acc: 0.7867, Train F1: 0.7867, Train Prec: 0.7867, Train Recall: 0.7867\n",
      "Epoch 14/1000 - Val Loss: 1.0225, Val Acc: 0.8027, Val F1: 0.8027, Val Prec: 0.8027, Val Recall: 0.8027\n",
      "\n",
      "Epoch 15/1000 - Train Loss: 0.9838, Train Acc: 0.7934, Train F1: 0.7934, Train Prec: 0.7934, Train Recall: 0.7934\n",
      "Epoch 15/1000 - Val Loss: 0.9753, Val Acc: 0.8056, Val F1: 0.8056, Val Prec: 0.8056, Val Recall: 0.8056\n",
      "\n",
      "Epoch 16/1000 - Train Loss: 0.9562, Train Acc: 0.8046, Train F1: 0.8046, Train Prec: 0.8046, Train Recall: 0.8046\n",
      "Epoch 16/1000 - Val Loss: 0.9459, Val Acc: 0.8056, Val F1: 0.8056, Val Prec: 0.8056, Val Recall: 0.8056\n",
      "\n",
      "Epoch 17/1000 - Train Loss: 0.9217, Train Acc: 0.8046, Train F1: 0.8046, Train Prec: 0.8046, Train Recall: 0.8046\n",
      "Epoch 17/1000 - Val Loss: 0.9070, Val Acc: 0.8096, Val F1: 0.8096, Val Prec: 0.8096, Val Recall: 0.8096\n",
      "\n",
      "Epoch 18/1000 - Train Loss: 0.8943, Train Acc: 0.8154, Train F1: 0.8154, Train Prec: 0.8154, Train Recall: 0.8154\n",
      "Epoch 18/1000 - Val Loss: 0.8769, Val Acc: 0.8146, Val F1: 0.8146, Val Prec: 0.8146, Val Recall: 0.8146\n",
      "\n",
      "Epoch 19/1000 - Train Loss: 0.8691, Train Acc: 0.8217, Train F1: 0.8217, Train Prec: 0.8217, Train Recall: 0.8217\n",
      "Epoch 19/1000 - Val Loss: 0.8715, Val Acc: 0.8236, Val F1: 0.8236, Val Prec: 0.8236, Val Recall: 0.8236\n",
      "\n",
      "Epoch 20/1000 - Train Loss: 0.8299, Train Acc: 0.8278, Train F1: 0.8278, Train Prec: 0.8278, Train Recall: 0.8278\n",
      "Epoch 20/1000 - Val Loss: 0.8306, Val Acc: 0.8226, Val F1: 0.8226, Val Prec: 0.8226, Val Recall: 0.8226\n",
      "\n",
      "Epoch 21/1000 - Train Loss: 0.8126, Train Acc: 0.8362, Train F1: 0.8362, Train Prec: 0.8362, Train Recall: 0.8362\n",
      "Epoch 21/1000 - Val Loss: 0.8213, Val Acc: 0.8269, Val F1: 0.8269, Val Prec: 0.8269, Val Recall: 0.8269\n",
      "\n",
      "Epoch 22/1000 - Train Loss: 0.7857, Train Acc: 0.8408, Train F1: 0.8408, Train Prec: 0.8408, Train Recall: 0.8408\n",
      "Epoch 22/1000 - Val Loss: 0.7919, Val Acc: 0.8352, Val F1: 0.8352, Val Prec: 0.8352, Val Recall: 0.8352\n",
      "\n",
      "Epoch 23/1000 - Train Loss: 0.7685, Train Acc: 0.8448, Train F1: 0.8448, Train Prec: 0.8448, Train Recall: 0.8448\n",
      "Epoch 23/1000 - Val Loss: 0.7737, Val Acc: 0.8329, Val F1: 0.8329, Val Prec: 0.8329, Val Recall: 0.8329\n",
      "\n",
      "Epoch 24/1000 - Train Loss: 0.7412, Train Acc: 0.8535, Train F1: 0.8535, Train Prec: 0.8535, Train Recall: 0.8535\n",
      "Epoch 24/1000 - Val Loss: 0.7668, Val Acc: 0.8372, Val F1: 0.8372, Val Prec: 0.8372, Val Recall: 0.8372\n",
      "\n",
      "Epoch 25/1000 - Train Loss: 0.7265, Train Acc: 0.8529, Train F1: 0.8529, Train Prec: 0.8529, Train Recall: 0.8529\n",
      "Epoch 25/1000 - Val Loss: 0.7339, Val Acc: 0.8412, Val F1: 0.8412, Val Prec: 0.8412, Val Recall: 0.8412\n",
      "\n",
      "Epoch 26/1000 - Train Loss: 0.7078, Train Acc: 0.8594, Train F1: 0.8594, Train Prec: 0.8594, Train Recall: 0.8594\n",
      "Epoch 26/1000 - Val Loss: 0.7164, Val Acc: 0.8492, Val F1: 0.8492, Val Prec: 0.8492, Val Recall: 0.8492\n",
      "\n",
      "Epoch 27/1000 - Train Loss: 0.6914, Train Acc: 0.8574, Train F1: 0.8574, Train Prec: 0.8574, Train Recall: 0.8574\n",
      "Epoch 27/1000 - Val Loss: 0.7053, Val Acc: 0.8522, Val F1: 0.8522, Val Prec: 0.8522, Val Recall: 0.8522\n",
      "\n",
      "Epoch 28/1000 - Train Loss: 0.6771, Train Acc: 0.8626, Train F1: 0.8626, Train Prec: 0.8626, Train Recall: 0.8626\n",
      "Epoch 28/1000 - Val Loss: 0.6972, Val Acc: 0.8538, Val F1: 0.8538, Val Prec: 0.8538, Val Recall: 0.8538\n",
      "\n",
      "Epoch 29/1000 - Train Loss: 0.6646, Train Acc: 0.8647, Train F1: 0.8647, Train Prec: 0.8647, Train Recall: 0.8647\n",
      "Epoch 29/1000 - Val Loss: 0.6800, Val Acc: 0.8551, Val F1: 0.8551, Val Prec: 0.8551, Val Recall: 0.8551\n",
      "\n",
      "Epoch 30/1000 - Train Loss: 0.6371, Train Acc: 0.8715, Train F1: 0.8715, Train Prec: 0.8715, Train Recall: 0.8715\n",
      "Epoch 30/1000 - Val Loss: 0.6595, Val Acc: 0.8505, Val F1: 0.8505, Val Prec: 0.8505, Val Recall: 0.8505\n",
      "\n",
      "Epoch 31/1000 - Train Loss: 0.6284, Train Acc: 0.8771, Train F1: 0.8771, Train Prec: 0.8771, Train Recall: 0.8771\n",
      "Epoch 31/1000 - Val Loss: 0.6522, Val Acc: 0.8585, Val F1: 0.8585, Val Prec: 0.8585, Val Recall: 0.8585\n",
      "\n",
      "Epoch 32/1000 - Train Loss: 0.6203, Train Acc: 0.8708, Train F1: 0.8708, Train Prec: 0.8708, Train Recall: 0.8708\n",
      "Epoch 32/1000 - Val Loss: 0.6474, Val Acc: 0.8578, Val F1: 0.8578, Val Prec: 0.8578, Val Recall: 0.8578\n",
      "\n",
      "Epoch 33/1000 - Train Loss: 0.5985, Train Acc: 0.8828, Train F1: 0.8828, Train Prec: 0.8828, Train Recall: 0.8828\n",
      "Epoch 33/1000 - Val Loss: 0.6313, Val Acc: 0.8518, Val F1: 0.8518, Val Prec: 0.8518, Val Recall: 0.8518\n",
      "\n",
      "Epoch 34/1000 - Train Loss: 0.5934, Train Acc: 0.8844, Train F1: 0.8844, Train Prec: 0.8844, Train Recall: 0.8844\n",
      "Epoch 34/1000 - Val Loss: 0.6184, Val Acc: 0.8605, Val F1: 0.8605, Val Prec: 0.8605, Val Recall: 0.8605\n",
      "\n",
      "Epoch 35/1000 - Train Loss: 0.5797, Train Acc: 0.8852, Train F1: 0.8852, Train Prec: 0.8852, Train Recall: 0.8852\n",
      "Epoch 35/1000 - Val Loss: 0.6153, Val Acc: 0.8558, Val F1: 0.8558, Val Prec: 0.8558, Val Recall: 0.8558\n",
      "\n",
      "Epoch 36/1000 - Train Loss: 0.5571, Train Acc: 0.8943, Train F1: 0.8943, Train Prec: 0.8943, Train Recall: 0.8943\n",
      "Epoch 36/1000 - Val Loss: 0.5928, Val Acc: 0.8621, Val F1: 0.8621, Val Prec: 0.8621, Val Recall: 0.8621\n",
      "\n",
      "Epoch 37/1000 - Train Loss: 0.5499, Train Acc: 0.8922, Train F1: 0.8922, Train Prec: 0.8922, Train Recall: 0.8922\n",
      "Epoch 37/1000 - Val Loss: 0.5804, Val Acc: 0.8615, Val F1: 0.8615, Val Prec: 0.8615, Val Recall: 0.8615\n",
      "\n",
      "Epoch 38/1000 - Train Loss: 0.5414, Train Acc: 0.8953, Train F1: 0.8953, Train Prec: 0.8953, Train Recall: 0.8953\n",
      "Epoch 38/1000 - Val Loss: 0.5802, Val Acc: 0.8701, Val F1: 0.8701, Val Prec: 0.8701, Val Recall: 0.8701\n",
      "\n",
      "Epoch 39/1000 - Train Loss: 0.5384, Train Acc: 0.8959, Train F1: 0.8959, Train Prec: 0.8959, Train Recall: 0.8959\n",
      "Epoch 39/1000 - Val Loss: 0.5660, Val Acc: 0.8698, Val F1: 0.8698, Val Prec: 0.8698, Val Recall: 0.8698\n",
      "\n",
      "Epoch 40/1000 - Train Loss: 0.5201, Train Acc: 0.9016, Train F1: 0.9016, Train Prec: 0.9016, Train Recall: 0.9016\n",
      "Epoch 40/1000 - Val Loss: 0.5611, Val Acc: 0.8688, Val F1: 0.8688, Val Prec: 0.8688, Val Recall: 0.8688\n",
      "\n",
      "Epoch 41/1000 - Train Loss: 0.5162, Train Acc: 0.9015, Train F1: 0.9015, Train Prec: 0.9015, Train Recall: 0.9015\n",
      "Epoch 41/1000 - Val Loss: 0.5522, Val Acc: 0.8728, Val F1: 0.8728, Val Prec: 0.8728, Val Recall: 0.8728\n",
      "\n",
      "Epoch 42/1000 - Train Loss: 0.5084, Train Acc: 0.9027, Train F1: 0.9027, Train Prec: 0.9027, Train Recall: 0.9027\n",
      "Epoch 42/1000 - Val Loss: 0.5515, Val Acc: 0.8754, Val F1: 0.8754, Val Prec: 0.8754, Val Recall: 0.8754\n",
      "\n",
      "Epoch 43/1000 - Train Loss: 0.4916, Train Acc: 0.9069, Train F1: 0.9069, Train Prec: 0.9069, Train Recall: 0.9069\n",
      "Epoch 43/1000 - Val Loss: 0.5382, Val Acc: 0.8751, Val F1: 0.8751, Val Prec: 0.8751, Val Recall: 0.8751\n",
      "\n",
      "Epoch 44/1000 - Train Loss: 0.4850, Train Acc: 0.9103, Train F1: 0.9103, Train Prec: 0.9103, Train Recall: 0.9103\n",
      "Epoch 44/1000 - Val Loss: 0.5271, Val Acc: 0.8704, Val F1: 0.8704, Val Prec: 0.8704, Val Recall: 0.8704\n",
      "\n",
      "Epoch 45/1000 - Train Loss: 0.4748, Train Acc: 0.9096, Train F1: 0.9096, Train Prec: 0.9096, Train Recall: 0.9096\n",
      "Epoch 45/1000 - Val Loss: 0.5253, Val Acc: 0.8751, Val F1: 0.8751, Val Prec: 0.8751, Val Recall: 0.8751\n",
      "\n",
      "Epoch 46/1000 - Train Loss: 0.4677, Train Acc: 0.9133, Train F1: 0.9133, Train Prec: 0.9133, Train Recall: 0.9133\n",
      "Epoch 46/1000 - Val Loss: 0.5231, Val Acc: 0.8817, Val F1: 0.8817, Val Prec: 0.8817, Val Recall: 0.8817\n",
      "\n",
      "Epoch 47/1000 - Train Loss: 0.4564, Train Acc: 0.9170, Train F1: 0.9170, Train Prec: 0.9170, Train Recall: 0.9170\n",
      "Epoch 47/1000 - Val Loss: 0.5098, Val Acc: 0.8754, Val F1: 0.8754, Val Prec: 0.8754, Val Recall: 0.8754\n",
      "\n",
      "Epoch 48/1000 - Train Loss: 0.4457, Train Acc: 0.9221, Train F1: 0.9221, Train Prec: 0.9221, Train Recall: 0.9221\n",
      "Epoch 48/1000 - Val Loss: 0.5072, Val Acc: 0.8754, Val F1: 0.8754, Val Prec: 0.8754, Val Recall: 0.8754\n",
      "\n",
      "Epoch 49/1000 - Train Loss: 0.4426, Train Acc: 0.9185, Train F1: 0.9185, Train Prec: 0.9185, Train Recall: 0.9185\n",
      "Epoch 49/1000 - Val Loss: 0.5120, Val Acc: 0.8841, Val F1: 0.8841, Val Prec: 0.8841, Val Recall: 0.8841\n",
      "\n",
      "Epoch 50/1000 - Train Loss: 0.4368, Train Acc: 0.9211, Train F1: 0.9211, Train Prec: 0.9211, Train Recall: 0.9211\n",
      "Epoch 50/1000 - Val Loss: 0.4993, Val Acc: 0.8850, Val F1: 0.8850, Val Prec: 0.8850, Val Recall: 0.8850\n",
      "\n",
      "Epoch 51/1000 - Train Loss: 0.4272, Train Acc: 0.9217, Train F1: 0.9217, Train Prec: 0.9217, Train Recall: 0.9217\n",
      "Epoch 51/1000 - Val Loss: 0.4859, Val Acc: 0.8827, Val F1: 0.8827, Val Prec: 0.8827, Val Recall: 0.8827\n",
      "\n",
      "Epoch 52/1000 - Train Loss: 0.4180, Train Acc: 0.9268, Train F1: 0.9268, Train Prec: 0.9268, Train Recall: 0.9268\n",
      "Epoch 52/1000 - Val Loss: 0.4800, Val Acc: 0.8854, Val F1: 0.8854, Val Prec: 0.8854, Val Recall: 0.8854\n",
      "\n",
      "Epoch 53/1000 - Train Loss: 0.4073, Train Acc: 0.9255, Train F1: 0.9255, Train Prec: 0.9255, Train Recall: 0.9255\n",
      "Epoch 53/1000 - Val Loss: 0.4824, Val Acc: 0.8831, Val F1: 0.8831, Val Prec: 0.8831, Val Recall: 0.8831\n",
      "\n",
      "Epoch 54/1000 - Train Loss: 0.4045, Train Acc: 0.9281, Train F1: 0.9281, Train Prec: 0.9281, Train Recall: 0.9281\n",
      "Epoch 54/1000 - Val Loss: 0.4835, Val Acc: 0.8884, Val F1: 0.8884, Val Prec: 0.8884, Val Recall: 0.8884\n",
      "\n",
      "Epoch 55/1000 - Train Loss: 0.3963, Train Acc: 0.9278, Train F1: 0.9278, Train Prec: 0.9278, Train Recall: 0.9278\n",
      "Epoch 55/1000 - Val Loss: 0.4685, Val Acc: 0.8837, Val F1: 0.8837, Val Prec: 0.8837, Val Recall: 0.8837\n",
      "\n",
      "Epoch 56/1000 - Train Loss: 0.3883, Train Acc: 0.9328, Train F1: 0.9328, Train Prec: 0.9328, Train Recall: 0.9328\n",
      "Epoch 56/1000 - Val Loss: 0.4591, Val Acc: 0.8924, Val F1: 0.8924, Val Prec: 0.8924, Val Recall: 0.8924\n",
      "\n",
      "Epoch 57/1000 - Train Loss: 0.3840, Train Acc: 0.9326, Train F1: 0.9326, Train Prec: 0.9326, Train Recall: 0.9326\n",
      "Epoch 57/1000 - Val Loss: 0.4584, Val Acc: 0.8887, Val F1: 0.8887, Val Prec: 0.8887, Val Recall: 0.8887\n",
      "\n",
      "Epoch 58/1000 - Train Loss: 0.3794, Train Acc: 0.9351, Train F1: 0.9351, Train Prec: 0.9351, Train Recall: 0.9351\n",
      "Epoch 58/1000 - Val Loss: 0.4502, Val Acc: 0.8910, Val F1: 0.8910, Val Prec: 0.8910, Val Recall: 0.8910\n",
      "\n",
      "Epoch 59/1000 - Train Loss: 0.3698, Train Acc: 0.9378, Train F1: 0.9378, Train Prec: 0.9378, Train Recall: 0.9378\n",
      "Epoch 59/1000 - Val Loss: 0.4531, Val Acc: 0.8884, Val F1: 0.8884, Val Prec: 0.8884, Val Recall: 0.8884\n",
      "\n",
      "Epoch 60/1000 - Train Loss: 0.3641, Train Acc: 0.9403, Train F1: 0.9403, Train Prec: 0.9403, Train Recall: 0.9403\n",
      "Epoch 60/1000 - Val Loss: 0.4426, Val Acc: 0.8924, Val F1: 0.8924, Val Prec: 0.8924, Val Recall: 0.8924\n",
      "\n",
      "Epoch 61/1000 - Train Loss: 0.3568, Train Acc: 0.9390, Train F1: 0.9390, Train Prec: 0.9390, Train Recall: 0.9390\n",
      "Epoch 61/1000 - Val Loss: 0.4445, Val Acc: 0.8904, Val F1: 0.8904, Val Prec: 0.8904, Val Recall: 0.8904\n",
      "\n",
      "Epoch 62/1000 - Train Loss: 0.3522, Train Acc: 0.9420, Train F1: 0.9420, Train Prec: 0.9420, Train Recall: 0.9420\n",
      "Epoch 62/1000 - Val Loss: 0.4332, Val Acc: 0.8900, Val F1: 0.8900, Val Prec: 0.8900, Val Recall: 0.8900\n",
      "\n",
      "Epoch 63/1000 - Train Loss: 0.3481, Train Acc: 0.9406, Train F1: 0.9406, Train Prec: 0.9406, Train Recall: 0.9406\n",
      "Epoch 63/1000 - Val Loss: 0.4349, Val Acc: 0.8937, Val F1: 0.8937, Val Prec: 0.8937, Val Recall: 0.8937\n",
      "\n",
      "Epoch 64/1000 - Train Loss: 0.3416, Train Acc: 0.9465, Train F1: 0.9465, Train Prec: 0.9465, Train Recall: 0.9465\n",
      "Epoch 64/1000 - Val Loss: 0.4260, Val Acc: 0.8944, Val F1: 0.8944, Val Prec: 0.8944, Val Recall: 0.8944\n",
      "\n",
      "Epoch 65/1000 - Train Loss: 0.3403, Train Acc: 0.9447, Train F1: 0.9447, Train Prec: 0.9447, Train Recall: 0.9447\n",
      "Epoch 65/1000 - Val Loss: 0.4169, Val Acc: 0.8940, Val F1: 0.8940, Val Prec: 0.8940, Val Recall: 0.8940\n",
      "\n",
      "Epoch 66/1000 - Train Loss: 0.3311, Train Acc: 0.9482, Train F1: 0.9482, Train Prec: 0.9482, Train Recall: 0.9482\n",
      "Epoch 66/1000 - Val Loss: 0.4195, Val Acc: 0.8920, Val F1: 0.8920, Val Prec: 0.8920, Val Recall: 0.8920\n",
      "\n",
      "Epoch 67/1000 - Train Loss: 0.3280, Train Acc: 0.9443, Train F1: 0.9443, Train Prec: 0.9443, Train Recall: 0.9443\n",
      "Epoch 67/1000 - Val Loss: 0.4216, Val Acc: 0.8880, Val F1: 0.8880, Val Prec: 0.8880, Val Recall: 0.8880\n",
      "\n",
      "Epoch 68/1000 - Train Loss: 0.3253, Train Acc: 0.9467, Train F1: 0.9467, Train Prec: 0.9467, Train Recall: 0.9467\n",
      "Epoch 68/1000 - Val Loss: 0.4156, Val Acc: 0.8924, Val F1: 0.8924, Val Prec: 0.8924, Val Recall: 0.8924\n",
      "\n",
      "Epoch 69/1000 - Train Loss: 0.3140, Train Acc: 0.9499, Train F1: 0.9499, Train Prec: 0.9499, Train Recall: 0.9499\n",
      "Epoch 69/1000 - Val Loss: 0.4079, Val Acc: 0.8937, Val F1: 0.8937, Val Prec: 0.8937, Val Recall: 0.8937\n",
      "\n",
      "Epoch 70/1000 - Train Loss: 0.3088, Train Acc: 0.9496, Train F1: 0.9496, Train Prec: 0.9496, Train Recall: 0.9496\n",
      "Epoch 70/1000 - Val Loss: 0.4190, Val Acc: 0.8960, Val F1: 0.8960, Val Prec: 0.8960, Val Recall: 0.8960\n",
      "\n",
      "Epoch 71/1000 - Train Loss: 0.3049, Train Acc: 0.9539, Train F1: 0.9539, Train Prec: 0.9539, Train Recall: 0.9539\n",
      "Epoch 71/1000 - Val Loss: 0.4033, Val Acc: 0.8947, Val F1: 0.8947, Val Prec: 0.8947, Val Recall: 0.8947\n",
      "\n",
      "Epoch 72/1000 - Train Loss: 0.3016, Train Acc: 0.9531, Train F1: 0.9531, Train Prec: 0.9531, Train Recall: 0.9531\n",
      "Epoch 72/1000 - Val Loss: 0.4076, Val Acc: 0.8934, Val F1: 0.8934, Val Prec: 0.8934, Val Recall: 0.8934\n",
      "\n",
      "Epoch 73/1000 - Train Loss: 0.2989, Train Acc: 0.9524, Train F1: 0.9524, Train Prec: 0.9524, Train Recall: 0.9524\n",
      "Epoch 73/1000 - Val Loss: 0.4040, Val Acc: 0.8967, Val F1: 0.8967, Val Prec: 0.8967, Val Recall: 0.8967\n",
      "\n",
      "Epoch 74/1000 - Train Loss: 0.2928, Train Acc: 0.9554, Train F1: 0.9554, Train Prec: 0.9554, Train Recall: 0.9554\n",
      "Epoch 74/1000 - Val Loss: 0.3977, Val Acc: 0.8963, Val F1: 0.8963, Val Prec: 0.8963, Val Recall: 0.8963\n",
      "\n",
      "Epoch 75/1000 - Train Loss: 0.2841, Train Acc: 0.9581, Train F1: 0.9581, Train Prec: 0.9581, Train Recall: 0.9581\n",
      "Epoch 75/1000 - Val Loss: 0.4068, Val Acc: 0.8967, Val F1: 0.8967, Val Prec: 0.8967, Val Recall: 0.8967\n",
      "\n",
      "Epoch 76/1000 - Train Loss: 0.2892, Train Acc: 0.9568, Train F1: 0.9568, Train Prec: 0.9568, Train Recall: 0.9568\n",
      "Epoch 76/1000 - Val Loss: 0.3939, Val Acc: 0.8987, Val F1: 0.8987, Val Prec: 0.8987, Val Recall: 0.8987\n",
      "\n",
      "Epoch 77/1000 - Train Loss: 0.2805, Train Acc: 0.9598, Train F1: 0.9598, Train Prec: 0.9598, Train Recall: 0.9598\n",
      "Epoch 77/1000 - Val Loss: 0.3914, Val Acc: 0.8963, Val F1: 0.8963, Val Prec: 0.8963, Val Recall: 0.8963\n",
      "\n",
      "Epoch 78/1000 - Train Loss: 0.2781, Train Acc: 0.9586, Train F1: 0.9586, Train Prec: 0.9586, Train Recall: 0.9586\n",
      "Epoch 78/1000 - Val Loss: 0.3941, Val Acc: 0.8973, Val F1: 0.8973, Val Prec: 0.8973, Val Recall: 0.8973\n",
      "\n",
      "Epoch 79/1000 - Train Loss: 0.2724, Train Acc: 0.9584, Train F1: 0.9584, Train Prec: 0.9584, Train Recall: 0.9584\n",
      "Epoch 79/1000 - Val Loss: 0.3851, Val Acc: 0.8987, Val F1: 0.8987, Val Prec: 0.8987, Val Recall: 0.8987\n",
      "\n",
      "Epoch 80/1000 - Train Loss: 0.2638, Train Acc: 0.9608, Train F1: 0.9608, Train Prec: 0.9608, Train Recall: 0.9608\n",
      "Epoch 80/1000 - Val Loss: 0.3773, Val Acc: 0.8983, Val F1: 0.8983, Val Prec: 0.8983, Val Recall: 0.8983\n",
      "\n",
      "Epoch 81/1000 - Train Loss: 0.2636, Train Acc: 0.9597, Train F1: 0.9597, Train Prec: 0.9597, Train Recall: 0.9597\n",
      "Epoch 81/1000 - Val Loss: 0.3769, Val Acc: 0.8990, Val F1: 0.8990, Val Prec: 0.8990, Val Recall: 0.8990\n",
      "\n",
      "Epoch 82/1000 - Train Loss: 0.2577, Train Acc: 0.9637, Train F1: 0.9637, Train Prec: 0.9637, Train Recall: 0.9637\n",
      "Epoch 82/1000 - Val Loss: 0.3912, Val Acc: 0.8977, Val F1: 0.8977, Val Prec: 0.8977, Val Recall: 0.8977\n",
      "\n",
      "Epoch 83/1000 - Train Loss: 0.2568, Train Acc: 0.9655, Train F1: 0.9655, Train Prec: 0.9655, Train Recall: 0.9655\n",
      "Epoch 83/1000 - Val Loss: 0.3745, Val Acc: 0.8997, Val F1: 0.8997, Val Prec: 0.8997, Val Recall: 0.8997\n",
      "\n",
      "Epoch 84/1000 - Train Loss: 0.2543, Train Acc: 0.9628, Train F1: 0.9628, Train Prec: 0.9628, Train Recall: 0.9628\n",
      "Epoch 84/1000 - Val Loss: 0.3732, Val Acc: 0.8960, Val F1: 0.8960, Val Prec: 0.8960, Val Recall: 0.8960\n",
      "\n",
      "Epoch 85/1000 - Train Loss: 0.2541, Train Acc: 0.9657, Train F1: 0.9657, Train Prec: 0.9657, Train Recall: 0.9657\n",
      "Epoch 85/1000 - Val Loss: 0.3700, Val Acc: 0.9010, Val F1: 0.9010, Val Prec: 0.9010, Val Recall: 0.9010\n",
      "\n",
      "Epoch 86/1000 - Train Loss: 0.2477, Train Acc: 0.9635, Train F1: 0.9635, Train Prec: 0.9635, Train Recall: 0.9635\n",
      "Epoch 86/1000 - Val Loss: 0.3679, Val Acc: 0.8987, Val F1: 0.8987, Val Prec: 0.8987, Val Recall: 0.8987\n",
      "\n",
      "Epoch 87/1000 - Train Loss: 0.2432, Train Acc: 0.9662, Train F1: 0.9662, Train Prec: 0.9662, Train Recall: 0.9662\n",
      "Epoch 87/1000 - Val Loss: 0.3784, Val Acc: 0.9007, Val F1: 0.9007, Val Prec: 0.9007, Val Recall: 0.9007\n",
      "\n",
      "Epoch 88/1000 - Train Loss: 0.2403, Train Acc: 0.9675, Train F1: 0.9675, Train Prec: 0.9675, Train Recall: 0.9675\n",
      "Epoch 88/1000 - Val Loss: 0.3734, Val Acc: 0.9007, Val F1: 0.9007, Val Prec: 0.9007, Val Recall: 0.9007\n",
      "\n",
      "Epoch 89/1000 - Train Loss: 0.2396, Train Acc: 0.9691, Train F1: 0.9691, Train Prec: 0.9691, Train Recall: 0.9691\n",
      "Epoch 89/1000 - Val Loss: 0.3714, Val Acc: 0.8977, Val F1: 0.8977, Val Prec: 0.8977, Val Recall: 0.8977\n",
      "\n",
      "Epoch 90/1000 - Train Loss: 0.2305, Train Acc: 0.9712, Train F1: 0.9712, Train Prec: 0.9712, Train Recall: 0.9712\n",
      "Epoch 90/1000 - Val Loss: 0.3655, Val Acc: 0.8963, Val F1: 0.8963, Val Prec: 0.8963, Val Recall: 0.8963\n",
      "\n",
      "Epoch 91/1000 - Train Loss: 0.2306, Train Acc: 0.9700, Train F1: 0.9700, Train Prec: 0.9700, Train Recall: 0.9700\n",
      "Epoch 91/1000 - Val Loss: 0.3568, Val Acc: 0.9007, Val F1: 0.9007, Val Prec: 0.9007, Val Recall: 0.9007\n",
      "\n",
      "Epoch 92/1000 - Train Loss: 0.2286, Train Acc: 0.9672, Train F1: 0.9672, Train Prec: 0.9672, Train Recall: 0.9672\n",
      "Epoch 92/1000 - Val Loss: 0.3573, Val Acc: 0.8977, Val F1: 0.8977, Val Prec: 0.8977, Val Recall: 0.8977\n",
      "\n",
      "Epoch 93/1000 - Train Loss: 0.2236, Train Acc: 0.9702, Train F1: 0.9702, Train Prec: 0.9702, Train Recall: 0.9702\n",
      "Epoch 93/1000 - Val Loss: 0.3523, Val Acc: 0.8987, Val F1: 0.8987, Val Prec: 0.8987, Val Recall: 0.8987\n",
      "\n",
      "Epoch 94/1000 - Train Loss: 0.2193, Train Acc: 0.9694, Train F1: 0.9694, Train Prec: 0.9694, Train Recall: 0.9694\n",
      "Epoch 94/1000 - Val Loss: 0.3547, Val Acc: 0.9000, Val F1: 0.9000, Val Prec: 0.9000, Val Recall: 0.9000\n",
      "\n",
      "Epoch 95/1000 - Train Loss: 0.2216, Train Acc: 0.9700, Train F1: 0.9700, Train Prec: 0.9700, Train Recall: 0.9700\n",
      "Epoch 95/1000 - Val Loss: 0.3551, Val Acc: 0.8997, Val F1: 0.8997, Val Prec: 0.8997, Val Recall: 0.8997\n",
      "\n",
      "Epoch 96/1000 - Train Loss: 0.2133, Train Acc: 0.9729, Train F1: 0.9729, Train Prec: 0.9729, Train Recall: 0.9729\n",
      "Epoch 96/1000 - Val Loss: 0.3550, Val Acc: 0.9000, Val F1: 0.9000, Val Prec: 0.9000, Val Recall: 0.9000\n",
      "\n",
      "Epoch 97/1000 - Train Loss: 0.2116, Train Acc: 0.9722, Train F1: 0.9722, Train Prec: 0.9722, Train Recall: 0.9722\n",
      "Epoch 97/1000 - Val Loss: 0.3478, Val Acc: 0.8997, Val F1: 0.8997, Val Prec: 0.8997, Val Recall: 0.8997\n",
      "\n",
      "Epoch 98/1000 - Train Loss: 0.2110, Train Acc: 0.9724, Train F1: 0.9724, Train Prec: 0.9724, Train Recall: 0.9724\n",
      "Epoch 98/1000 - Val Loss: 0.3451, Val Acc: 0.9023, Val F1: 0.9023, Val Prec: 0.9023, Val Recall: 0.9023\n",
      "\n",
      "Epoch 99/1000 - Train Loss: 0.2051, Train Acc: 0.9729, Train F1: 0.9729, Train Prec: 0.9729, Train Recall: 0.9729\n",
      "Epoch 99/1000 - Val Loss: 0.3458, Val Acc: 0.9007, Val F1: 0.9007, Val Prec: 0.9007, Val Recall: 0.9007\n",
      "\n",
      "Epoch 100/1000 - Train Loss: 0.2016, Train Acc: 0.9742, Train F1: 0.9742, Train Prec: 0.9742, Train Recall: 0.9742\n",
      "Epoch 100/1000 - Val Loss: 0.3423, Val Acc: 0.9017, Val F1: 0.9017, Val Prec: 0.9017, Val Recall: 0.9017\n",
      "\n",
      "Epoch 101/1000 - Train Loss: 0.2015, Train Acc: 0.9745, Train F1: 0.9745, Train Prec: 0.9745, Train Recall: 0.9745\n",
      "Epoch 101/1000 - Val Loss: 0.3381, Val Acc: 0.9003, Val F1: 0.9003, Val Prec: 0.9003, Val Recall: 0.9003\n",
      "\n",
      "Epoch 102/1000 - Train Loss: 0.1958, Train Acc: 0.9754, Train F1: 0.9754, Train Prec: 0.9754, Train Recall: 0.9754\n",
      "Epoch 102/1000 - Val Loss: 0.3421, Val Acc: 0.9033, Val F1: 0.9033, Val Prec: 0.9033, Val Recall: 0.9033\n",
      "\n",
      "Epoch 103/1000 - Train Loss: 0.1960, Train Acc: 0.9748, Train F1: 0.9748, Train Prec: 0.9748, Train Recall: 0.9748\n",
      "Epoch 103/1000 - Val Loss: 0.3399, Val Acc: 0.9027, Val F1: 0.9027, Val Prec: 0.9027, Val Recall: 0.9027\n",
      "\n",
      "Epoch 104/1000 - Train Loss: 0.1921, Train Acc: 0.9774, Train F1: 0.9774, Train Prec: 0.9774, Train Recall: 0.9774\n",
      "Epoch 104/1000 - Val Loss: 0.3402, Val Acc: 0.9053, Val F1: 0.9053, Val Prec: 0.9053, Val Recall: 0.9053\n",
      "\n",
      "Epoch 105/1000 - Train Loss: 0.1920, Train Acc: 0.9766, Train F1: 0.9766, Train Prec: 0.9766, Train Recall: 0.9766\n",
      "Epoch 105/1000 - Val Loss: 0.3356, Val Acc: 0.9000, Val F1: 0.9000, Val Prec: 0.9000, Val Recall: 0.9000\n",
      "\n",
      "Epoch 106/1000 - Train Loss: 0.1893, Train Acc: 0.9761, Train F1: 0.9761, Train Prec: 0.9761, Train Recall: 0.9761\n",
      "Epoch 106/1000 - Val Loss: 0.3410, Val Acc: 0.9013, Val F1: 0.9013, Val Prec: 0.9013, Val Recall: 0.9013\n",
      "\n",
      "Epoch 107/1000 - Train Loss: 0.1871, Train Acc: 0.9765, Train F1: 0.9765, Train Prec: 0.9765, Train Recall: 0.9765\n",
      "Epoch 107/1000 - Val Loss: 0.3325, Val Acc: 0.9030, Val F1: 0.9030, Val Prec: 0.9030, Val Recall: 0.9030\n",
      "\n",
      "Epoch 108/1000 - Train Loss: 0.1830, Train Acc: 0.9774, Train F1: 0.9774, Train Prec: 0.9774, Train Recall: 0.9774\n",
      "Epoch 108/1000 - Val Loss: 0.3349, Val Acc: 0.9000, Val F1: 0.9000, Val Prec: 0.9000, Val Recall: 0.9000\n",
      "\n",
      "Epoch 109/1000 - Train Loss: 0.1811, Train Acc: 0.9774, Train F1: 0.9774, Train Prec: 0.9774, Train Recall: 0.9774\n",
      "Epoch 109/1000 - Val Loss: 0.3293, Val Acc: 0.8993, Val F1: 0.8993, Val Prec: 0.8993, Val Recall: 0.8993\n",
      "\n",
      "Epoch 110/1000 - Train Loss: 0.1797, Train Acc: 0.9776, Train F1: 0.9776, Train Prec: 0.9776, Train Recall: 0.9776\n",
      "Epoch 110/1000 - Val Loss: 0.3293, Val Acc: 0.9027, Val F1: 0.9027, Val Prec: 0.9027, Val Recall: 0.9027\n",
      "\n",
      "Epoch 111/1000 - Train Loss: 0.1753, Train Acc: 0.9794, Train F1: 0.9794, Train Prec: 0.9794, Train Recall: 0.9794\n",
      "Epoch 111/1000 - Val Loss: 0.3334, Val Acc: 0.9003, Val F1: 0.9003, Val Prec: 0.9003, Val Recall: 0.9003\n",
      "\n",
      "Epoch 112/1000 - Train Loss: 0.1783, Train Acc: 0.9795, Train F1: 0.9795, Train Prec: 0.9795, Train Recall: 0.9795\n",
      "Epoch 112/1000 - Val Loss: 0.3264, Val Acc: 0.8987, Val F1: 0.8987, Val Prec: 0.8987, Val Recall: 0.8987\n",
      "\n",
      "Epoch 113/1000 - Train Loss: 0.1693, Train Acc: 0.9812, Train F1: 0.9812, Train Prec: 0.9812, Train Recall: 0.9812\n",
      "Epoch 113/1000 - Val Loss: 0.3293, Val Acc: 0.9060, Val F1: 0.9060, Val Prec: 0.9060, Val Recall: 0.9060\n",
      "\n",
      "Epoch 114/1000 - Train Loss: 0.1686, Train Acc: 0.9791, Train F1: 0.9791, Train Prec: 0.9791, Train Recall: 0.9791\n",
      "Epoch 114/1000 - Val Loss: 0.3365, Val Acc: 0.9037, Val F1: 0.9037, Val Prec: 0.9037, Val Recall: 0.9037\n",
      "\n",
      "Epoch 115/1000 - Train Loss: 0.1702, Train Acc: 0.9789, Train F1: 0.9789, Train Prec: 0.9789, Train Recall: 0.9789\n",
      "Epoch 115/1000 - Val Loss: 0.3270, Val Acc: 0.9047, Val F1: 0.9047, Val Prec: 0.9047, Val Recall: 0.9047\n",
      "\n",
      "Epoch 116/1000 - Train Loss: 0.1642, Train Acc: 0.9821, Train F1: 0.9821, Train Prec: 0.9821, Train Recall: 0.9821\n",
      "Epoch 116/1000 - Val Loss: 0.3249, Val Acc: 0.9017, Val F1: 0.9017, Val Prec: 0.9017, Val Recall: 0.9017\n",
      "\n",
      "Epoch 117/1000 - Train Loss: 0.1646, Train Acc: 0.9821, Train F1: 0.9821, Train Prec: 0.9821, Train Recall: 0.9821\n",
      "Epoch 117/1000 - Val Loss: 0.3207, Val Acc: 0.9030, Val F1: 0.9030, Val Prec: 0.9030, Val Recall: 0.9030\n",
      "\n",
      "Epoch 118/1000 - Train Loss: 0.1605, Train Acc: 0.9803, Train F1: 0.9803, Train Prec: 0.9803, Train Recall: 0.9803\n",
      "Epoch 118/1000 - Val Loss: 0.3218, Val Acc: 0.9043, Val F1: 0.9043, Val Prec: 0.9043, Val Recall: 0.9043\n",
      "\n",
      "Epoch 119/1000 - Train Loss: 0.1630, Train Acc: 0.9812, Train F1: 0.9812, Train Prec: 0.9812, Train Recall: 0.9812\n",
      "Epoch 119/1000 - Val Loss: 0.3199, Val Acc: 0.9020, Val F1: 0.9020, Val Prec: 0.9020, Val Recall: 0.9020\n",
      "\n",
      "Epoch 120/1000 - Train Loss: 0.1580, Train Acc: 0.9825, Train F1: 0.9825, Train Prec: 0.9825, Train Recall: 0.9825\n",
      "Epoch 120/1000 - Val Loss: 0.3173, Val Acc: 0.9023, Val F1: 0.9023, Val Prec: 0.9023, Val Recall: 0.9023\n",
      "\n",
      "Epoch 121/1000 - Train Loss: 0.1551, Train Acc: 0.9822, Train F1: 0.9822, Train Prec: 0.9822, Train Recall: 0.9822\n",
      "Epoch 121/1000 - Val Loss: 0.3241, Val Acc: 0.9076, Val F1: 0.9076, Val Prec: 0.9076, Val Recall: 0.9076\n",
      "\n",
      "Epoch 122/1000 - Train Loss: 0.1545, Train Acc: 0.9828, Train F1: 0.9828, Train Prec: 0.9828, Train Recall: 0.9828\n",
      "Epoch 122/1000 - Val Loss: 0.3204, Val Acc: 0.9083, Val F1: 0.9083, Val Prec: 0.9083, Val Recall: 0.9083\n",
      "\n",
      "Epoch 123/1000 - Train Loss: 0.1498, Train Acc: 0.9823, Train F1: 0.9823, Train Prec: 0.9823, Train Recall: 0.9823\n",
      "Epoch 123/1000 - Val Loss: 0.3181, Val Acc: 0.9053, Val F1: 0.9053, Val Prec: 0.9053, Val Recall: 0.9053\n",
      "\n",
      "Epoch 124/1000 - Train Loss: 0.1491, Train Acc: 0.9841, Train F1: 0.9841, Train Prec: 0.9841, Train Recall: 0.9841\n",
      "Epoch 124/1000 - Val Loss: 0.3161, Val Acc: 0.9076, Val F1: 0.9076, Val Prec: 0.9076, Val Recall: 0.9076\n",
      "\n",
      "Epoch 125/1000 - Train Loss: 0.1485, Train Acc: 0.9842, Train F1: 0.9842, Train Prec: 0.9842, Train Recall: 0.9842\n",
      "Epoch 125/1000 - Val Loss: 0.3220, Val Acc: 0.9056, Val F1: 0.9056, Val Prec: 0.9056, Val Recall: 0.9056\n",
      "\n",
      "Epoch 126/1000 - Train Loss: 0.1474, Train Acc: 0.9848, Train F1: 0.9848, Train Prec: 0.9848, Train Recall: 0.9848\n",
      "Epoch 126/1000 - Val Loss: 0.3231, Val Acc: 0.9027, Val F1: 0.9027, Val Prec: 0.9027, Val Recall: 0.9027\n",
      "\n",
      "Epoch 127/1000 - Train Loss: 0.1460, Train Acc: 0.9841, Train F1: 0.9841, Train Prec: 0.9841, Train Recall: 0.9841\n",
      "Epoch 127/1000 - Val Loss: 0.3114, Val Acc: 0.9020, Val F1: 0.9020, Val Prec: 0.9020, Val Recall: 0.9020\n",
      "\n",
      "Epoch 128/1000 - Train Loss: 0.1455, Train Acc: 0.9842, Train F1: 0.9842, Train Prec: 0.9842, Train Recall: 0.9842\n",
      "Epoch 128/1000 - Val Loss: 0.3091, Val Acc: 0.9047, Val F1: 0.9047, Val Prec: 0.9047, Val Recall: 0.9047\n",
      "\n",
      "Epoch 129/1000 - Train Loss: 0.1423, Train Acc: 0.9855, Train F1: 0.9855, Train Prec: 0.9855, Train Recall: 0.9855\n",
      "Epoch 129/1000 - Val Loss: 0.3131, Val Acc: 0.9017, Val F1: 0.9017, Val Prec: 0.9017, Val Recall: 0.9017\n",
      "\n",
      "Epoch 130/1000 - Train Loss: 0.1429, Train Acc: 0.9835, Train F1: 0.9835, Train Prec: 0.9835, Train Recall: 0.9835\n",
      "Epoch 130/1000 - Val Loss: 0.3323, Val Acc: 0.9050, Val F1: 0.9050, Val Prec: 0.9050, Val Recall: 0.9050\n",
      "\n",
      "Epoch 131/1000 - Train Loss: 0.1384, Train Acc: 0.9843, Train F1: 0.9843, Train Prec: 0.9843, Train Recall: 0.9843\n",
      "Epoch 131/1000 - Val Loss: 0.3106, Val Acc: 0.9030, Val F1: 0.9030, Val Prec: 0.9030, Val Recall: 0.9030\n",
      "\n",
      "Epoch 132/1000 - Train Loss: 0.1346, Train Acc: 0.9855, Train F1: 0.9855, Train Prec: 0.9855, Train Recall: 0.9855\n",
      "Epoch 132/1000 - Val Loss: 0.3107, Val Acc: 0.9070, Val F1: 0.9070, Val Prec: 0.9070, Val Recall: 0.9070\n",
      "\n",
      "Epoch 133/1000 - Train Loss: 0.1392, Train Acc: 0.9863, Train F1: 0.9863, Train Prec: 0.9863, Train Recall: 0.9863\n",
      "Epoch 133/1000 - Val Loss: 0.3105, Val Acc: 0.9063, Val F1: 0.9063, Val Prec: 0.9063, Val Recall: 0.9063\n",
      "\n",
      "Epoch 134/1000 - Train Loss: 0.1334, Train Acc: 0.9858, Train F1: 0.9858, Train Prec: 0.9858, Train Recall: 0.9858\n",
      "Epoch 134/1000 - Val Loss: 0.3111, Val Acc: 0.9047, Val F1: 0.9047, Val Prec: 0.9047, Val Recall: 0.9047\n",
      "\n",
      "Epoch 135/1000 - Train Loss: 0.1359, Train Acc: 0.9873, Train F1: 0.9873, Train Prec: 0.9873, Train Recall: 0.9873\n",
      "Epoch 135/1000 - Val Loss: 0.3108, Val Acc: 0.9053, Val F1: 0.9053, Val Prec: 0.9053, Val Recall: 0.9053\n",
      "\n",
      "Epoch 136/1000 - Train Loss: 0.1310, Train Acc: 0.9885, Train F1: 0.9885, Train Prec: 0.9885, Train Recall: 0.9885\n",
      "Epoch 136/1000 - Val Loss: 0.3188, Val Acc: 0.9063, Val F1: 0.9063, Val Prec: 0.9063, Val Recall: 0.9063\n",
      "\n",
      "Epoch 137/1000 - Train Loss: 0.1302, Train Acc: 0.9882, Train F1: 0.9882, Train Prec: 0.9882, Train Recall: 0.9882\n",
      "Epoch 137/1000 - Val Loss: 0.3149, Val Acc: 0.9066, Val F1: 0.9066, Val Prec: 0.9066, Val Recall: 0.9066\n",
      "\n",
      "Epoch 138/1000 - Train Loss: 0.1268, Train Acc: 0.9876, Train F1: 0.9876, Train Prec: 0.9876, Train Recall: 0.9876\n",
      "Epoch 138/1000 - Val Loss: 0.3101, Val Acc: 0.9047, Val F1: 0.9047, Val Prec: 0.9047, Val Recall: 0.9047\n",
      "\n",
      "Epoch 139/1000 - Train Loss: 0.1244, Train Acc: 0.9878, Train F1: 0.9878, Train Prec: 0.9878, Train Recall: 0.9878\n",
      "Epoch 139/1000 - Val Loss: 0.3031, Val Acc: 0.9043, Val F1: 0.9043, Val Prec: 0.9043, Val Recall: 0.9043\n",
      "\n",
      "Epoch 140/1000 - Train Loss: 0.1226, Train Acc: 0.9879, Train F1: 0.9879, Train Prec: 0.9879, Train Recall: 0.9879\n",
      "Epoch 140/1000 - Val Loss: 0.3153, Val Acc: 0.9053, Val F1: 0.9053, Val Prec: 0.9053, Val Recall: 0.9053\n",
      "\n",
      "Epoch 141/1000 - Train Loss: 0.1280, Train Acc: 0.9886, Train F1: 0.9886, Train Prec: 0.9886, Train Recall: 0.9886\n",
      "Epoch 141/1000 - Val Loss: 0.3009, Val Acc: 0.9047, Val F1: 0.9047, Val Prec: 0.9047, Val Recall: 0.9047\n",
      "\n",
      "Epoch 142/1000 - Train Loss: 0.1244, Train Acc: 0.9875, Train F1: 0.9875, Train Prec: 0.9875, Train Recall: 0.9875\n",
      "Epoch 142/1000 - Val Loss: 0.3073, Val Acc: 0.9083, Val F1: 0.9083, Val Prec: 0.9083, Val Recall: 0.9083\n",
      "\n",
      "Epoch 143/1000 - Train Loss: 0.1198, Train Acc: 0.9896, Train F1: 0.9896, Train Prec: 0.9896, Train Recall: 0.9896\n",
      "Epoch 143/1000 - Val Loss: 0.3012, Val Acc: 0.9106, Val F1: 0.9106, Val Prec: 0.9106, Val Recall: 0.9106\n",
      "\n",
      "Epoch 144/1000 - Train Loss: 0.1164, Train Acc: 0.9900, Train F1: 0.9900, Train Prec: 0.9900, Train Recall: 0.9900\n",
      "Epoch 144/1000 - Val Loss: 0.3005, Val Acc: 0.9060, Val F1: 0.9060, Val Prec: 0.9060, Val Recall: 0.9060\n",
      "\n",
      "Epoch 145/1000 - Train Loss: 0.1180, Train Acc: 0.9903, Train F1: 0.9903, Train Prec: 0.9903, Train Recall: 0.9903\n",
      "Epoch 145/1000 - Val Loss: 0.3007, Val Acc: 0.9080, Val F1: 0.9080, Val Prec: 0.9080, Val Recall: 0.9080\n",
      "\n",
      "Epoch 146/1000 - Train Loss: 0.1179, Train Acc: 0.9899, Train F1: 0.9899, Train Prec: 0.9899, Train Recall: 0.9899\n",
      "Epoch 146/1000 - Val Loss: 0.3158, Val Acc: 0.9083, Val F1: 0.9083, Val Prec: 0.9083, Val Recall: 0.9083\n",
      "\n",
      "Epoch 147/1000 - Train Loss: 0.1142, Train Acc: 0.9919, Train F1: 0.9919, Train Prec: 0.9919, Train Recall: 0.9919\n",
      "Epoch 147/1000 - Val Loss: 0.2971, Val Acc: 0.9090, Val F1: 0.9090, Val Prec: 0.9090, Val Recall: 0.9090\n",
      "\n",
      "Epoch 148/1000 - Train Loss: 0.1146, Train Acc: 0.9900, Train F1: 0.9900, Train Prec: 0.9900, Train Recall: 0.9900\n",
      "Epoch 148/1000 - Val Loss: 0.3032, Val Acc: 0.9056, Val F1: 0.9056, Val Prec: 0.9056, Val Recall: 0.9056\n",
      "\n",
      "Epoch 149/1000 - Train Loss: 0.1118, Train Acc: 0.9915, Train F1: 0.9915, Train Prec: 0.9915, Train Recall: 0.9915\n",
      "Epoch 149/1000 - Val Loss: 0.2976, Val Acc: 0.9053, Val F1: 0.9053, Val Prec: 0.9053, Val Recall: 0.9053\n",
      "\n",
      "Epoch 150/1000 - Train Loss: 0.1107, Train Acc: 0.9902, Train F1: 0.9902, Train Prec: 0.9902, Train Recall: 0.9902\n",
      "Epoch 150/1000 - Val Loss: 0.3011, Val Acc: 0.9073, Val F1: 0.9073, Val Prec: 0.9073, Val Recall: 0.9073\n",
      "\n",
      "Epoch 151/1000 - Train Loss: 0.1108, Train Acc: 0.9915, Train F1: 0.9915, Train Prec: 0.9915, Train Recall: 0.9915\n",
      "Epoch 151/1000 - Val Loss: 0.2983, Val Acc: 0.9063, Val F1: 0.9063, Val Prec: 0.9063, Val Recall: 0.9063\n",
      "\n",
      "Epoch 152/1000 - Train Loss: 0.1126, Train Acc: 0.9916, Train F1: 0.9916, Train Prec: 0.9916, Train Recall: 0.9916\n",
      "Epoch 152/1000 - Val Loss: 0.2989, Val Acc: 0.9050, Val F1: 0.9050, Val Prec: 0.9050, Val Recall: 0.9050\n",
      "\n",
      "Epoch 153/1000 - Train Loss: 0.1065, Train Acc: 0.9923, Train F1: 0.9923, Train Prec: 0.9923, Train Recall: 0.9923\n",
      "Epoch 153/1000 - Val Loss: 0.2969, Val Acc: 0.9086, Val F1: 0.9086, Val Prec: 0.9086, Val Recall: 0.9086\n",
      "\n",
      "Epoch 154/1000 - Train Loss: 0.1102, Train Acc: 0.9913, Train F1: 0.9913, Train Prec: 0.9913, Train Recall: 0.9913\n",
      "Epoch 154/1000 - Val Loss: 0.3014, Val Acc: 0.9093, Val F1: 0.9093, Val Prec: 0.9093, Val Recall: 0.9093\n",
      "\n",
      "Epoch 155/1000 - Train Loss: 0.1028, Train Acc: 0.9926, Train F1: 0.9926, Train Prec: 0.9926, Train Recall: 0.9926\n",
      "Epoch 155/1000 - Val Loss: 0.2988, Val Acc: 0.9063, Val F1: 0.9063, Val Prec: 0.9063, Val Recall: 0.9063\n",
      "\n",
      "Epoch 156/1000 - Train Loss: 0.1032, Train Acc: 0.9925, Train F1: 0.9925, Train Prec: 0.9925, Train Recall: 0.9925\n",
      "Epoch 156/1000 - Val Loss: 0.2954, Val Acc: 0.9063, Val F1: 0.9063, Val Prec: 0.9063, Val Recall: 0.9063\n",
      "\n",
      "Epoch 157/1000 - Train Loss: 0.1039, Train Acc: 0.9923, Train F1: 0.9923, Train Prec: 0.9923, Train Recall: 0.9923\n",
      "Epoch 157/1000 - Val Loss: 0.2973, Val Acc: 0.9066, Val F1: 0.9066, Val Prec: 0.9066, Val Recall: 0.9066\n",
      "\n",
      "Epoch 158/1000 - Train Loss: 0.1020, Train Acc: 0.9926, Train F1: 0.9926, Train Prec: 0.9926, Train Recall: 0.9926\n",
      "Epoch 158/1000 - Val Loss: 0.2965, Val Acc: 0.9066, Val F1: 0.9066, Val Prec: 0.9066, Val Recall: 0.9066\n",
      "\n",
      "Epoch 159/1000 - Train Loss: 0.1001, Train Acc: 0.9939, Train F1: 0.9939, Train Prec: 0.9939, Train Recall: 0.9939\n",
      "Epoch 159/1000 - Val Loss: 0.2926, Val Acc: 0.9090, Val F1: 0.9090, Val Prec: 0.9090, Val Recall: 0.9090\n",
      "\n",
      "Epoch 160/1000 - Train Loss: 0.1001, Train Acc: 0.9944, Train F1: 0.9944, Train Prec: 0.9944, Train Recall: 0.9944\n",
      "Epoch 160/1000 - Val Loss: 0.2897, Val Acc: 0.9100, Val F1: 0.9100, Val Prec: 0.9100, Val Recall: 0.9100\n",
      "\n",
      "Epoch 161/1000 - Train Loss: 0.0986, Train Acc: 0.9942, Train F1: 0.9942, Train Prec: 0.9942, Train Recall: 0.9942\n",
      "Epoch 161/1000 - Val Loss: 0.2943, Val Acc: 0.9060, Val F1: 0.9060, Val Prec: 0.9060, Val Recall: 0.9060\n",
      "\n",
      "Epoch 162/1000 - Train Loss: 0.0961, Train Acc: 0.9936, Train F1: 0.9936, Train Prec: 0.9936, Train Recall: 0.9936\n",
      "Epoch 162/1000 - Val Loss: 0.2910, Val Acc: 0.9100, Val F1: 0.9100, Val Prec: 0.9100, Val Recall: 0.9100\n",
      "\n",
      "Epoch 163/1000 - Train Loss: 0.0981, Train Acc: 0.9930, Train F1: 0.9930, Train Prec: 0.9930, Train Recall: 0.9930\n",
      "Epoch 163/1000 - Val Loss: 0.2945, Val Acc: 0.9083, Val F1: 0.9083, Val Prec: 0.9083, Val Recall: 0.9083\n",
      "\n",
      "Epoch 164/1000 - Train Loss: 0.0955, Train Acc: 0.9944, Train F1: 0.9944, Train Prec: 0.9944, Train Recall: 0.9944\n",
      "Epoch 164/1000 - Val Loss: 0.2930, Val Acc: 0.9047, Val F1: 0.9047, Val Prec: 0.9047, Val Recall: 0.9047\n",
      "\n",
      "Epoch 165/1000 - Train Loss: 0.0964, Train Acc: 0.9950, Train F1: 0.9950, Train Prec: 0.9950, Train Recall: 0.9950\n",
      "Epoch 165/1000 - Val Loss: 0.2890, Val Acc: 0.9093, Val F1: 0.9093, Val Prec: 0.9093, Val Recall: 0.9093\n",
      "\n",
      "Epoch 166/1000 - Train Loss: 0.0950, Train Acc: 0.9946, Train F1: 0.9946, Train Prec: 0.9946, Train Recall: 0.9946\n",
      "Epoch 166/1000 - Val Loss: 0.2903, Val Acc: 0.9103, Val F1: 0.9103, Val Prec: 0.9103, Val Recall: 0.9103\n",
      "\n",
      "Epoch 167/1000 - Train Loss: 0.0917, Train Acc: 0.9947, Train F1: 0.9947, Train Prec: 0.9947, Train Recall: 0.9947\n",
      "Epoch 167/1000 - Val Loss: 0.2916, Val Acc: 0.9083, Val F1: 0.9083, Val Prec: 0.9083, Val Recall: 0.9083\n",
      "\n",
      "Epoch 168/1000 - Train Loss: 0.0922, Train Acc: 0.9949, Train F1: 0.9949, Train Prec: 0.9949, Train Recall: 0.9949\n",
      "Epoch 168/1000 - Val Loss: 0.2889, Val Acc: 0.9080, Val F1: 0.9080, Val Prec: 0.9080, Val Recall: 0.9080\n",
      "\n",
      "Epoch 169/1000 - Train Loss: 0.0900, Train Acc: 0.9947, Train F1: 0.9947, Train Prec: 0.9947, Train Recall: 0.9947\n",
      "Epoch 169/1000 - Val Loss: 0.2855, Val Acc: 0.9103, Val F1: 0.9103, Val Prec: 0.9103, Val Recall: 0.9103\n",
      "\n",
      "Epoch 170/1000 - Train Loss: 0.0906, Train Acc: 0.9939, Train F1: 0.9939, Train Prec: 0.9939, Train Recall: 0.9939\n",
      "Epoch 170/1000 - Val Loss: 0.2880, Val Acc: 0.9086, Val F1: 0.9086, Val Prec: 0.9086, Val Recall: 0.9086\n",
      "\n",
      "Epoch 171/1000 - Train Loss: 0.0928, Train Acc: 0.9946, Train F1: 0.9946, Train Prec: 0.9946, Train Recall: 0.9946\n",
      "Epoch 171/1000 - Val Loss: 0.2931, Val Acc: 0.9080, Val F1: 0.9080, Val Prec: 0.9080, Val Recall: 0.9080\n",
      "\n",
      "Epoch 172/1000 - Train Loss: 0.0889, Train Acc: 0.9953, Train F1: 0.9953, Train Prec: 0.9953, Train Recall: 0.9953\n",
      "Epoch 172/1000 - Val Loss: 0.2928, Val Acc: 0.9086, Val F1: 0.9086, Val Prec: 0.9086, Val Recall: 0.9086\n",
      "\n",
      "Epoch 173/1000 - Train Loss: 0.0878, Train Acc: 0.9954, Train F1: 0.9954, Train Prec: 0.9954, Train Recall: 0.9954\n",
      "Epoch 173/1000 - Val Loss: 0.2838, Val Acc: 0.9093, Val F1: 0.9093, Val Prec: 0.9093, Val Recall: 0.9093\n",
      "\n",
      "Epoch 174/1000 - Train Loss: 0.0856, Train Acc: 0.9973, Train F1: 0.9973, Train Prec: 0.9973, Train Recall: 0.9973\n",
      "Epoch 174/1000 - Val Loss: 0.2860, Val Acc: 0.9126, Val F1: 0.9126, Val Prec: 0.9126, Val Recall: 0.9126\n",
      "\n",
      "Epoch 175/1000 - Train Loss: 0.0855, Train Acc: 0.9959, Train F1: 0.9959, Train Prec: 0.9959, Train Recall: 0.9959\n",
      "Epoch 175/1000 - Val Loss: 0.2857, Val Acc: 0.9120, Val F1: 0.9120, Val Prec: 0.9120, Val Recall: 0.9120\n",
      "\n",
      "Epoch 176/1000 - Train Loss: 0.0870, Train Acc: 0.9949, Train F1: 0.9949, Train Prec: 0.9949, Train Recall: 0.9949\n",
      "Epoch 176/1000 - Val Loss: 0.2872, Val Acc: 0.9110, Val F1: 0.9110, Val Prec: 0.9110, Val Recall: 0.9110\n",
      "\n",
      "Epoch 177/1000 - Train Loss: 0.0884, Train Acc: 0.9949, Train F1: 0.9949, Train Prec: 0.9949, Train Recall: 0.9949\n",
      "Epoch 177/1000 - Val Loss: 0.2819, Val Acc: 0.9096, Val F1: 0.9096, Val Prec: 0.9096, Val Recall: 0.9096\n",
      "\n",
      "Epoch 178/1000 - Train Loss: 0.0854, Train Acc: 0.9963, Train F1: 0.9963, Train Prec: 0.9963, Train Recall: 0.9963\n",
      "Epoch 178/1000 - Val Loss: 0.2839, Val Acc: 0.9110, Val F1: 0.9110, Val Prec: 0.9110, Val Recall: 0.9110\n",
      "\n",
      "Epoch 179/1000 - Train Loss: 0.0838, Train Acc: 0.9962, Train F1: 0.9962, Train Prec: 0.9962, Train Recall: 0.9962\n",
      "Epoch 179/1000 - Val Loss: 0.2916, Val Acc: 0.9063, Val F1: 0.9063, Val Prec: 0.9063, Val Recall: 0.9063\n",
      "\n",
      "Epoch 180/1000 - Train Loss: 0.0847, Train Acc: 0.9964, Train F1: 0.9964, Train Prec: 0.9964, Train Recall: 0.9964\n",
      "Epoch 180/1000 - Val Loss: 0.2839, Val Acc: 0.9103, Val F1: 0.9103, Val Prec: 0.9103, Val Recall: 0.9103\n",
      "\n",
      "Epoch 181/1000 - Train Loss: 0.0814, Train Acc: 0.9967, Train F1: 0.9967, Train Prec: 0.9967, Train Recall: 0.9967\n",
      "Epoch 181/1000 - Val Loss: 0.2832, Val Acc: 0.9083, Val F1: 0.9083, Val Prec: 0.9083, Val Recall: 0.9083\n",
      "\n",
      "Epoch 182/1000 - Train Loss: 0.0803, Train Acc: 0.9970, Train F1: 0.9970, Train Prec: 0.9970, Train Recall: 0.9970\n",
      "Epoch 182/1000 - Val Loss: 0.2929, Val Acc: 0.9093, Val F1: 0.9093, Val Prec: 0.9093, Val Recall: 0.9093\n",
      "\n",
      "Epoch 183/1000 - Train Loss: 0.0788, Train Acc: 0.9964, Train F1: 0.9964, Train Prec: 0.9964, Train Recall: 0.9964\n",
      "Epoch 183/1000 - Val Loss: 0.2841, Val Acc: 0.9073, Val F1: 0.9073, Val Prec: 0.9073, Val Recall: 0.9073\n",
      "\n",
      "Epoch 184/1000 - Train Loss: 0.0807, Train Acc: 0.9967, Train F1: 0.9967, Train Prec: 0.9967, Train Recall: 0.9967\n",
      "Epoch 184/1000 - Val Loss: 0.2828, Val Acc: 0.9076, Val F1: 0.9076, Val Prec: 0.9076, Val Recall: 0.9076\n",
      "\n",
      "Epoch 185/1000 - Train Loss: 0.0776, Train Acc: 0.9963, Train F1: 0.9963, Train Prec: 0.9963, Train Recall: 0.9963\n",
      "Epoch 185/1000 - Val Loss: 0.2837, Val Acc: 0.9116, Val F1: 0.9116, Val Prec: 0.9116, Val Recall: 0.9116\n",
      "\n",
      "Epoch 186/1000 - Train Loss: 0.0779, Train Acc: 0.9973, Train F1: 0.9973, Train Prec: 0.9973, Train Recall: 0.9973\n",
      "Epoch 186/1000 - Val Loss: 0.2811, Val Acc: 0.9113, Val F1: 0.9113, Val Prec: 0.9113, Val Recall: 0.9113\n",
      "\n",
      "Epoch 187/1000 - Train Loss: 0.0754, Train Acc: 0.9976, Train F1: 0.9976, Train Prec: 0.9976, Train Recall: 0.9976\n",
      "Epoch 187/1000 - Val Loss: 0.2814, Val Acc: 0.9126, Val F1: 0.9126, Val Prec: 0.9126, Val Recall: 0.9126\n",
      "\n",
      "Epoch 188/1000 - Train Loss: 0.0762, Train Acc: 0.9981, Train F1: 0.9981, Train Prec: 0.9981, Train Recall: 0.9981\n",
      "Epoch 188/1000 - Val Loss: 0.2860, Val Acc: 0.9096, Val F1: 0.9096, Val Prec: 0.9096, Val Recall: 0.9096\n",
      "\n",
      "Epoch 189/1000 - Train Loss: 0.0731, Train Acc: 0.9980, Train F1: 0.9980, Train Prec: 0.9980, Train Recall: 0.9980\n",
      "Epoch 189/1000 - Val Loss: 0.2841, Val Acc: 0.9100, Val F1: 0.9100, Val Prec: 0.9100, Val Recall: 0.9100\n",
      "\n",
      "Epoch 190/1000 - Train Loss: 0.0745, Train Acc: 0.9979, Train F1: 0.9979, Train Prec: 0.9979, Train Recall: 0.9979\n",
      "Epoch 190/1000 - Val Loss: 0.2778, Val Acc: 0.9136, Val F1: 0.9136, Val Prec: 0.9136, Val Recall: 0.9136\n",
      "\n",
      "Epoch 191/1000 - Train Loss: 0.0745, Train Acc: 0.9976, Train F1: 0.9976, Train Prec: 0.9976, Train Recall: 0.9976\n",
      "Epoch 191/1000 - Val Loss: 0.2815, Val Acc: 0.9116, Val F1: 0.9116, Val Prec: 0.9116, Val Recall: 0.9116\n",
      "\n",
      "Epoch 192/1000 - Train Loss: 0.0738, Train Acc: 0.9967, Train F1: 0.9967, Train Prec: 0.9967, Train Recall: 0.9967\n",
      "Epoch 192/1000 - Val Loss: 0.2801, Val Acc: 0.9110, Val F1: 0.9110, Val Prec: 0.9110, Val Recall: 0.9110\n",
      "\n",
      "Epoch 193/1000 - Train Loss: 0.0727, Train Acc: 0.9972, Train F1: 0.9972, Train Prec: 0.9972, Train Recall: 0.9972\n",
      "Epoch 193/1000 - Val Loss: 0.2822, Val Acc: 0.9100, Val F1: 0.9100, Val Prec: 0.9100, Val Recall: 0.9100\n",
      "\n",
      "Epoch 194/1000 - Train Loss: 0.0728, Train Acc: 0.9981, Train F1: 0.9981, Train Prec: 0.9981, Train Recall: 0.9981\n",
      "Epoch 194/1000 - Val Loss: 0.2759, Val Acc: 0.9133, Val F1: 0.9133, Val Prec: 0.9133, Val Recall: 0.9133\n",
      "\n",
      "Epoch 195/1000 - Train Loss: 0.0709, Train Acc: 0.9983, Train F1: 0.9983, Train Prec: 0.9983, Train Recall: 0.9983\n",
      "Epoch 195/1000 - Val Loss: 0.2821, Val Acc: 0.9093, Val F1: 0.9093, Val Prec: 0.9093, Val Recall: 0.9093\n",
      "\n",
      "Epoch 196/1000 - Train Loss: 0.0721, Train Acc: 0.9972, Train F1: 0.9972, Train Prec: 0.9972, Train Recall: 0.9972\n",
      "Epoch 196/1000 - Val Loss: 0.3125, Val Acc: 0.9120, Val F1: 0.9120, Val Prec: 0.9120, Val Recall: 0.9120\n",
      "\n",
      "Epoch 197/1000 - Train Loss: 0.0724, Train Acc: 0.9977, Train F1: 0.9977, Train Prec: 0.9977, Train Recall: 0.9977\n",
      "Epoch 197/1000 - Val Loss: 0.2834, Val Acc: 0.9146, Val F1: 0.9146, Val Prec: 0.9146, Val Recall: 0.9146\n",
      "\n",
      "Epoch 198/1000 - Train Loss: 0.0709, Train Acc: 0.9981, Train F1: 0.9981, Train Prec: 0.9981, Train Recall: 0.9981\n",
      "Epoch 198/1000 - Val Loss: 0.2797, Val Acc: 0.9110, Val F1: 0.9110, Val Prec: 0.9110, Val Recall: 0.9110\n",
      "\n",
      "Epoch 199/1000 - Train Loss: 0.0692, Train Acc: 0.9983, Train F1: 0.9983, Train Prec: 0.9983, Train Recall: 0.9983\n",
      "Epoch 199/1000 - Val Loss: 0.2821, Val Acc: 0.9080, Val F1: 0.9080, Val Prec: 0.9080, Val Recall: 0.9080\n",
      "\n",
      "Epoch 200/1000 - Train Loss: 0.0701, Train Acc: 0.9981, Train F1: 0.9981, Train Prec: 0.9981, Train Recall: 0.9981\n",
      "Epoch 200/1000 - Val Loss: 0.2763, Val Acc: 0.9120, Val F1: 0.9120, Val Prec: 0.9120, Val Recall: 0.9120\n",
      "\n",
      "Epoch 201/1000 - Train Loss: 0.0685, Train Acc: 0.9979, Train F1: 0.9979, Train Prec: 0.9979, Train Recall: 0.9979\n",
      "Epoch 201/1000 - Val Loss: 0.2786, Val Acc: 0.9110, Val F1: 0.9110, Val Prec: 0.9110, Val Recall: 0.9110\n",
      "\n",
      "Epoch 202/1000 - Train Loss: 0.0671, Train Acc: 0.9984, Train F1: 0.9984, Train Prec: 0.9984, Train Recall: 0.9984\n",
      "Epoch 202/1000 - Val Loss: 0.2774, Val Acc: 0.9106, Val F1: 0.9106, Val Prec: 0.9106, Val Recall: 0.9106\n",
      "\n",
      "Epoch 203/1000 - Train Loss: 0.0665, Train Acc: 0.9987, Train F1: 0.9987, Train Prec: 0.9987, Train Recall: 0.9987\n",
      "Epoch 203/1000 - Val Loss: 0.2812, Val Acc: 0.9133, Val F1: 0.9133, Val Prec: 0.9133, Val Recall: 0.9133\n",
      "\n",
      "Epoch 204/1000 - Train Loss: 0.0652, Train Acc: 0.9989, Train F1: 0.9989, Train Prec: 0.9989, Train Recall: 0.9989\n",
      "Epoch 204/1000 - Val Loss: 0.2870, Val Acc: 0.9123, Val F1: 0.9123, Val Prec: 0.9123, Val Recall: 0.9123\n",
      "\n",
      "Epoch 205/1000 - Train Loss: 0.0661, Train Acc: 0.9986, Train F1: 0.9986, Train Prec: 0.9986, Train Recall: 0.9986\n",
      "Epoch 205/1000 - Val Loss: 0.2734, Val Acc: 0.9120, Val F1: 0.9120, Val Prec: 0.9120, Val Recall: 0.9120\n",
      "\n",
      "Epoch 206/1000 - Train Loss: 0.0638, Train Acc: 0.9989, Train F1: 0.9989, Train Prec: 0.9989, Train Recall: 0.9989\n",
      "Epoch 206/1000 - Val Loss: 0.2801, Val Acc: 0.9100, Val F1: 0.9100, Val Prec: 0.9100, Val Recall: 0.9100\n",
      "\n",
      "Epoch 207/1000 - Train Loss: 0.0646, Train Acc: 0.9994, Train F1: 0.9994, Train Prec: 0.9994, Train Recall: 0.9994\n",
      "Epoch 207/1000 - Val Loss: 0.2766, Val Acc: 0.9126, Val F1: 0.9126, Val Prec: 0.9126, Val Recall: 0.9126\n",
      "\n",
      "Epoch 208/1000 - Train Loss: 0.0651, Train Acc: 0.9986, Train F1: 0.9986, Train Prec: 0.9986, Train Recall: 0.9986\n",
      "Epoch 208/1000 - Val Loss: 0.2765, Val Acc: 0.9126, Val F1: 0.9126, Val Prec: 0.9126, Val Recall: 0.9126\n",
      "\n",
      "Epoch 209/1000 - Train Loss: 0.0647, Train Acc: 0.9983, Train F1: 0.9983, Train Prec: 0.9983, Train Recall: 0.9983\n",
      "Epoch 209/1000 - Val Loss: 0.2794, Val Acc: 0.9110, Val F1: 0.9110, Val Prec: 0.9110, Val Recall: 0.9110\n",
      "\n",
      "Epoch 210/1000 - Train Loss: 0.0639, Train Acc: 0.9986, Train F1: 0.9986, Train Prec: 0.9986, Train Recall: 0.9986\n",
      "Epoch 210/1000 - Val Loss: 0.2817, Val Acc: 0.9066, Val F1: 0.9066, Val Prec: 0.9066, Val Recall: 0.9066\n",
      "\n",
      "Epoch 211/1000 - Train Loss: 0.0628, Train Acc: 0.9984, Train F1: 0.9984, Train Prec: 0.9984, Train Recall: 0.9984\n",
      "Epoch 211/1000 - Val Loss: 0.3063, Val Acc: 0.9093, Val F1: 0.9093, Val Prec: 0.9093, Val Recall: 0.9093\n",
      "\n",
      "Epoch 212/1000 - Train Loss: 0.0619, Train Acc: 0.9981, Train F1: 0.9981, Train Prec: 0.9981, Train Recall: 0.9981\n",
      "Epoch 212/1000 - Val Loss: 0.2835, Val Acc: 0.9116, Val F1: 0.9116, Val Prec: 0.9116, Val Recall: 0.9116\n",
      "\n",
      "Epoch 213/1000 - Train Loss: 0.0609, Train Acc: 0.9989, Train F1: 0.9989, Train Prec: 0.9989, Train Recall: 0.9989\n",
      "Epoch 213/1000 - Val Loss: 0.2775, Val Acc: 0.9086, Val F1: 0.9086, Val Prec: 0.9086, Val Recall: 0.9086\n",
      "\n",
      "Epoch 214/1000 - Train Loss: 0.0605, Train Acc: 0.9991, Train F1: 0.9991, Train Prec: 0.9991, Train Recall: 0.9991\n",
      "Epoch 214/1000 - Val Loss: 0.2730, Val Acc: 0.9120, Val F1: 0.9120, Val Prec: 0.9120, Val Recall: 0.9120\n",
      "\n",
      "Epoch 215/1000 - Train Loss: 0.0609, Train Acc: 0.9993, Train F1: 0.9993, Train Prec: 0.9993, Train Recall: 0.9993\n",
      "Epoch 215/1000 - Val Loss: 0.2751, Val Acc: 0.9116, Val F1: 0.9116, Val Prec: 0.9116, Val Recall: 0.9116\n",
      "\n",
      "Epoch 216/1000 - Train Loss: 0.0622, Train Acc: 0.9983, Train F1: 0.9983, Train Prec: 0.9983, Train Recall: 0.9983\n",
      "Epoch 216/1000 - Val Loss: 0.2728, Val Acc: 0.9100, Val F1: 0.9100, Val Prec: 0.9100, Val Recall: 0.9100\n",
      "\n",
      "Epoch 217/1000 - Train Loss: 0.0599, Train Acc: 0.9991, Train F1: 0.9991, Train Prec: 0.9991, Train Recall: 0.9991\n",
      "Epoch 217/1000 - Val Loss: 0.2744, Val Acc: 0.9126, Val F1: 0.9126, Val Prec: 0.9126, Val Recall: 0.9126\n",
      "\n",
      "Epoch 218/1000 - Train Loss: 0.0586, Train Acc: 0.9990, Train F1: 0.9990, Train Prec: 0.9990, Train Recall: 0.9990\n",
      "Epoch 218/1000 - Val Loss: 0.2781, Val Acc: 0.9133, Val F1: 0.9133, Val Prec: 0.9133, Val Recall: 0.9133\n",
      "\n",
      "Epoch 219/1000 - Train Loss: 0.0578, Train Acc: 0.9993, Train F1: 0.9993, Train Prec: 0.9993, Train Recall: 0.9993\n",
      "Epoch 219/1000 - Val Loss: 0.2722, Val Acc: 0.9110, Val F1: 0.9110, Val Prec: 0.9110, Val Recall: 0.9110\n",
      "\n",
      "Epoch 220/1000 - Train Loss: 0.0574, Train Acc: 0.9987, Train F1: 0.9987, Train Prec: 0.9987, Train Recall: 0.9987\n",
      "Epoch 220/1000 - Val Loss: 0.2779, Val Acc: 0.9116, Val F1: 0.9116, Val Prec: 0.9116, Val Recall: 0.9116\n",
      "\n",
      "Epoch 221/1000 - Train Loss: 0.0575, Train Acc: 0.9996, Train F1: 0.9996, Train Prec: 0.9996, Train Recall: 0.9996\n",
      "Epoch 221/1000 - Val Loss: 0.2783, Val Acc: 0.9120, Val F1: 0.9120, Val Prec: 0.9120, Val Recall: 0.9120\n",
      "\n",
      "Epoch 222/1000 - Train Loss: 0.0572, Train Acc: 0.9991, Train F1: 0.9991, Train Prec: 0.9991, Train Recall: 0.9991\n",
      "Epoch 222/1000 - Val Loss: 0.2732, Val Acc: 0.9106, Val F1: 0.9106, Val Prec: 0.9106, Val Recall: 0.9106\n",
      "\n",
      "Epoch 223/1000 - Train Loss: 0.0565, Train Acc: 0.9997, Train F1: 0.9997, Train Prec: 0.9997, Train Recall: 0.9997\n",
      "Epoch 223/1000 - Val Loss: 0.2821, Val Acc: 0.9093, Val F1: 0.9093, Val Prec: 0.9093, Val Recall: 0.9093\n",
      "\n",
      "Epoch 224/1000 - Train Loss: 0.0557, Train Acc: 0.9996, Train F1: 0.9996, Train Prec: 0.9996, Train Recall: 0.9996\n",
      "Epoch 224/1000 - Val Loss: 0.2727, Val Acc: 0.9126, Val F1: 0.9126, Val Prec: 0.9126, Val Recall: 0.9126\n",
      "\n",
      "Epoch 225/1000 - Train Loss: 0.0548, Train Acc: 0.9991, Train F1: 0.9991, Train Prec: 0.9991, Train Recall: 0.9991\n",
      "Epoch 225/1000 - Val Loss: 0.2747, Val Acc: 0.9126, Val F1: 0.9126, Val Prec: 0.9126, Val Recall: 0.9126\n",
      "\n",
      "Epoch 226/1000 - Train Loss: 0.0548, Train Acc: 0.9991, Train F1: 0.9991, Train Prec: 0.9991, Train Recall: 0.9991\n",
      "Epoch 226/1000 - Val Loss: 0.2828, Val Acc: 0.9100, Val F1: 0.9100, Val Prec: 0.9100, Val Recall: 0.9100\n",
      "\n",
      "Epoch 227/1000 - Train Loss: 0.0526, Train Acc: 0.9997, Train F1: 0.9997, Train Prec: 0.9997, Train Recall: 0.9997\n",
      "Epoch 227/1000 - Val Loss: 0.2740, Val Acc: 0.9106, Val F1: 0.9106, Val Prec: 0.9106, Val Recall: 0.9106\n",
      "\n",
      "Epoch 228/1000 - Train Loss: 0.0539, Train Acc: 0.9996, Train F1: 0.9996, Train Prec: 0.9996, Train Recall: 0.9996\n",
      "Epoch 228/1000 - Val Loss: 0.2723, Val Acc: 0.9103, Val F1: 0.9103, Val Prec: 0.9103, Val Recall: 0.9103\n",
      "\n",
      "Epoch 229/1000 - Train Loss: 0.0570, Train Acc: 0.9991, Train F1: 0.9991, Train Prec: 0.9991, Train Recall: 0.9991\n",
      "Epoch 229/1000 - Val Loss: 0.2750, Val Acc: 0.9123, Val F1: 0.9123, Val Prec: 0.9123, Val Recall: 0.9123\n",
      "\n",
      "Epoch 230/1000 - Train Loss: 0.0545, Train Acc: 0.9993, Train F1: 0.9993, Train Prec: 0.9993, Train Recall: 0.9993\n",
      "Epoch 230/1000 - Val Loss: 0.2732, Val Acc: 0.9100, Val F1: 0.9100, Val Prec: 0.9100, Val Recall: 0.9100\n",
      "\n",
      "Epoch 231/1000 - Train Loss: 0.0532, Train Acc: 0.9991, Train F1: 0.9991, Train Prec: 0.9991, Train Recall: 0.9991\n",
      "Epoch 231/1000 - Val Loss: 0.2731, Val Acc: 0.9103, Val F1: 0.9103, Val Prec: 0.9103, Val Recall: 0.9103\n",
      "\n",
      "Epoch 232/1000 - Train Loss: 0.0516, Train Acc: 0.9994, Train F1: 0.9994, Train Prec: 0.9994, Train Recall: 0.9994\n",
      "Epoch 232/1000 - Val Loss: 0.2711, Val Acc: 0.9126, Val F1: 0.9126, Val Prec: 0.9126, Val Recall: 0.9126\n",
      "\n",
      "Epoch 233/1000 - Train Loss: 0.0538, Train Acc: 0.9994, Train F1: 0.9994, Train Prec: 0.9994, Train Recall: 0.9994\n",
      "Epoch 233/1000 - Val Loss: 0.2681, Val Acc: 0.9113, Val F1: 0.9113, Val Prec: 0.9113, Val Recall: 0.9113\n",
      "\n",
      "Epoch 234/1000 - Train Loss: 0.0521, Train Acc: 0.9994, Train F1: 0.9994, Train Prec: 0.9994, Train Recall: 0.9994\n",
      "Epoch 234/1000 - Val Loss: 0.2728, Val Acc: 0.9126, Val F1: 0.9126, Val Prec: 0.9126, Val Recall: 0.9126\n",
      "\n",
      "Epoch 235/1000 - Train Loss: 0.0525, Train Acc: 0.9991, Train F1: 0.9991, Train Prec: 0.9991, Train Recall: 0.9991\n",
      "Epoch 235/1000 - Val Loss: 0.2675, Val Acc: 0.9110, Val F1: 0.9110, Val Prec: 0.9110, Val Recall: 0.9110\n",
      "\n",
      "Epoch 236/1000 - Train Loss: 0.0520, Train Acc: 0.9990, Train F1: 0.9990, Train Prec: 0.9990, Train Recall: 0.9990\n",
      "Epoch 236/1000 - Val Loss: 0.2708, Val Acc: 0.9100, Val F1: 0.9100, Val Prec: 0.9100, Val Recall: 0.9100\n",
      "\n",
      "Epoch 237/1000 - Train Loss: 0.0506, Train Acc: 0.9996, Train F1: 0.9996, Train Prec: 0.9996, Train Recall: 0.9996\n",
      "Epoch 237/1000 - Val Loss: 0.2714, Val Acc: 0.9116, Val F1: 0.9116, Val Prec: 0.9116, Val Recall: 0.9116\n",
      "\n",
      "Epoch 238/1000 - Train Loss: 0.0497, Train Acc: 0.9997, Train F1: 0.9997, Train Prec: 0.9997, Train Recall: 0.9997\n",
      "Epoch 238/1000 - Val Loss: 0.2679, Val Acc: 0.9113, Val F1: 0.9113, Val Prec: 0.9113, Val Recall: 0.9113\n",
      "\n",
      "Epoch 239/1000 - Train Loss: 0.0516, Train Acc: 0.9994, Train F1: 0.9994, Train Prec: 0.9994, Train Recall: 0.9994\n",
      "Epoch 239/1000 - Val Loss: 0.2704, Val Acc: 0.9136, Val F1: 0.9136, Val Prec: 0.9136, Val Recall: 0.9136\n",
      "\n",
      "Epoch 240/1000 - Train Loss: 0.0493, Train Acc: 0.9994, Train F1: 0.9994, Train Prec: 0.9994, Train Recall: 0.9994\n",
      "Epoch 240/1000 - Val Loss: 0.2725, Val Acc: 0.9106, Val F1: 0.9106, Val Prec: 0.9106, Val Recall: 0.9106\n",
      "\n",
      "Epoch 241/1000 - Train Loss: 0.0500, Train Acc: 1.0000, Train F1: 1.0000, Train Prec: 1.0000, Train Recall: 1.0000\n",
      "Epoch 241/1000 - Val Loss: 0.2719, Val Acc: 0.9116, Val F1: 0.9116, Val Prec: 0.9116, Val Recall: 0.9116\n",
      "\n",
      "Epoch 242/1000 - Train Loss: 0.0500, Train Acc: 0.9993, Train F1: 0.9993, Train Prec: 0.9993, Train Recall: 0.9993\n",
      "Epoch 242/1000 - Val Loss: 0.2676, Val Acc: 0.9106, Val F1: 0.9106, Val Prec: 0.9106, Val Recall: 0.9106\n",
      "\n",
      "Epoch 243/1000 - Train Loss: 0.0497, Train Acc: 0.9999, Train F1: 0.9999, Train Prec: 0.9999, Train Recall: 0.9999\n",
      "Epoch 243/1000 - Val Loss: 0.2678, Val Acc: 0.9106, Val F1: 0.9106, Val Prec: 0.9106, Val Recall: 0.9106\n",
      "\n",
      "Epoch 244/1000 - Train Loss: 0.0498, Train Acc: 0.9997, Train F1: 0.9997, Train Prec: 0.9997, Train Recall: 0.9997\n",
      "Epoch 244/1000 - Val Loss: 0.2732, Val Acc: 0.9116, Val F1: 0.9116, Val Prec: 0.9116, Val Recall: 0.9116\n",
      "\n",
      "Epoch 245/1000 - Train Loss: 0.0474, Train Acc: 0.9997, Train F1: 0.9997, Train Prec: 0.9997, Train Recall: 0.9997\n",
      "Epoch 245/1000 - Val Loss: 0.2701, Val Acc: 0.9106, Val F1: 0.9106, Val Prec: 0.9106, Val Recall: 0.9106\n",
      "\n",
      "Epoch 246/1000 - Train Loss: 0.0471, Train Acc: 1.0000, Train F1: 1.0000, Train Prec: 1.0000, Train Recall: 1.0000\n",
      "Epoch 246/1000 - Val Loss: 0.2692, Val Acc: 0.9133, Val F1: 0.9133, Val Prec: 0.9133, Val Recall: 0.9133\n",
      "\n",
      "Epoch 247/1000 - Train Loss: 0.0479, Train Acc: 0.9999, Train F1: 0.9999, Train Prec: 0.9999, Train Recall: 0.9999\n",
      "Epoch 247/1000 - Val Loss: 0.2765, Val Acc: 0.9083, Val F1: 0.9083, Val Prec: 0.9083, Val Recall: 0.9083\n",
      "\n",
      "Epoch 248/1000 - Train Loss: 0.0473, Train Acc: 0.9996, Train F1: 0.9996, Train Prec: 0.9996, Train Recall: 0.9996\n",
      "Epoch 248/1000 - Val Loss: 0.2675, Val Acc: 0.9126, Val F1: 0.9126, Val Prec: 0.9126, Val Recall: 0.9126\n",
      "\n",
      "Epoch 249/1000 - Train Loss: 0.0493, Train Acc: 0.9997, Train F1: 0.9997, Train Prec: 0.9997, Train Recall: 0.9997\n",
      "Epoch 249/1000 - Val Loss: 0.2752, Val Acc: 0.9100, Val F1: 0.9100, Val Prec: 0.9100, Val Recall: 0.9100\n",
      "\n",
      "Epoch 250/1000 - Train Loss: 0.0477, Train Acc: 0.9993, Train F1: 0.9993, Train Prec: 0.9993, Train Recall: 0.9993\n",
      "Epoch 250/1000 - Val Loss: 0.2762, Val Acc: 0.9110, Val F1: 0.9110, Val Prec: 0.9110, Val Recall: 0.9110\n",
      "\n",
      "Epoch 251/1000 - Train Loss: 0.0456, Train Acc: 0.9999, Train F1: 0.9999, Train Prec: 0.9999, Train Recall: 0.9999\n",
      "Epoch 251/1000 - Val Loss: 0.2687, Val Acc: 0.9143, Val F1: 0.9143, Val Prec: 0.9143, Val Recall: 0.9143\n",
      "\n",
      "Epoch 252/1000 - Train Loss: 0.0447, Train Acc: 0.9993, Train F1: 0.9993, Train Prec: 0.9993, Train Recall: 0.9993\n",
      "Epoch 252/1000 - Val Loss: 0.2719, Val Acc: 0.9110, Val F1: 0.9110, Val Prec: 0.9110, Val Recall: 0.9110\n",
      "\n",
      "Epoch 253/1000 - Train Loss: 0.0461, Train Acc: 0.9997, Train F1: 0.9997, Train Prec: 0.9997, Train Recall: 0.9997\n",
      "Epoch 253/1000 - Val Loss: 0.2705, Val Acc: 0.9140, Val F1: 0.9140, Val Prec: 0.9140, Val Recall: 0.9140\n",
      "\n",
      "Epoch 254/1000 - Train Loss: 0.0458, Train Acc: 0.9991, Train F1: 0.9991, Train Prec: 0.9991, Train Recall: 0.9991\n",
      "Epoch 254/1000 - Val Loss: 0.2722, Val Acc: 0.9100, Val F1: 0.9100, Val Prec: 0.9100, Val Recall: 0.9100\n",
      "\n",
      "Epoch 255/1000 - Train Loss: 0.0456, Train Acc: 0.9996, Train F1: 0.9996, Train Prec: 0.9996, Train Recall: 0.9996\n",
      "Epoch 255/1000 - Val Loss: 0.2734, Val Acc: 0.9096, Val F1: 0.9096, Val Prec: 0.9096, Val Recall: 0.9096\n",
      "\n",
      "Epoch 256/1000 - Train Loss: 0.0430, Train Acc: 0.9996, Train F1: 0.9996, Train Prec: 0.9996, Train Recall: 0.9996\n",
      "Epoch 256/1000 - Val Loss: 0.2674, Val Acc: 0.9100, Val F1: 0.9100, Val Prec: 0.9100, Val Recall: 0.9100\n",
      "\n",
      "Epoch 257/1000 - Train Loss: 0.0429, Train Acc: 0.9997, Train F1: 0.9997, Train Prec: 0.9997, Train Recall: 0.9997\n",
      "Epoch 257/1000 - Val Loss: 0.2658, Val Acc: 0.9130, Val F1: 0.9130, Val Prec: 0.9130, Val Recall: 0.9130\n",
      "\n",
      "Epoch 258/1000 - Train Loss: 0.0435, Train Acc: 0.9999, Train F1: 0.9999, Train Prec: 0.9999, Train Recall: 0.9999\n",
      "Epoch 258/1000 - Val Loss: 0.2846, Val Acc: 0.9106, Val F1: 0.9106, Val Prec: 0.9106, Val Recall: 0.9106\n",
      "\n",
      "Epoch 259/1000 - Train Loss: 0.0438, Train Acc: 0.9994, Train F1: 0.9994, Train Prec: 0.9994, Train Recall: 0.9994\n",
      "Epoch 259/1000 - Val Loss: 0.2713, Val Acc: 0.9110, Val F1: 0.9110, Val Prec: 0.9110, Val Recall: 0.9110\n",
      "\n",
      "Epoch 260/1000 - Train Loss: 0.0447, Train Acc: 0.9997, Train F1: 0.9997, Train Prec: 0.9997, Train Recall: 0.9997\n",
      "Epoch 260/1000 - Val Loss: 0.2639, Val Acc: 0.9136, Val F1: 0.9136, Val Prec: 0.9136, Val Recall: 0.9136\n",
      "\n",
      "Epoch 261/1000 - Train Loss: 0.0428, Train Acc: 0.9997, Train F1: 0.9997, Train Prec: 0.9997, Train Recall: 0.9997\n",
      "Epoch 261/1000 - Val Loss: 0.2658, Val Acc: 0.9123, Val F1: 0.9123, Val Prec: 0.9123, Val Recall: 0.9123\n",
      "\n",
      "Epoch 262/1000 - Train Loss: 0.0432, Train Acc: 1.0000, Train F1: 1.0000, Train Prec: 1.0000, Train Recall: 1.0000\n",
      "Epoch 262/1000 - Val Loss: 0.2712, Val Acc: 0.9086, Val F1: 0.9086, Val Prec: 0.9086, Val Recall: 0.9086\n",
      "\n",
      "Epoch 263/1000 - Train Loss: 0.0438, Train Acc: 0.9994, Train F1: 0.9994, Train Prec: 0.9994, Train Recall: 0.9994\n",
      "Epoch 263/1000 - Val Loss: 0.2801, Val Acc: 0.9096, Val F1: 0.9096, Val Prec: 0.9096, Val Recall: 0.9096\n",
      "\n",
      "Epoch 264/1000 - Train Loss: 0.0429, Train Acc: 1.0000, Train F1: 1.0000, Train Prec: 1.0000, Train Recall: 1.0000\n",
      "Epoch 264/1000 - Val Loss: 0.2677, Val Acc: 0.9120, Val F1: 0.9120, Val Prec: 0.9120, Val Recall: 0.9120\n",
      "\n",
      "Epoch 265/1000 - Train Loss: 0.0415, Train Acc: 0.9996, Train F1: 0.9996, Train Prec: 0.9996, Train Recall: 0.9996\n",
      "Epoch 265/1000 - Val Loss: 0.2723, Val Acc: 0.9083, Val F1: 0.9083, Val Prec: 0.9083, Val Recall: 0.9083\n",
      "\n",
      "Epoch 266/1000 - Train Loss: 0.0411, Train Acc: 0.9993, Train F1: 0.9993, Train Prec: 0.9993, Train Recall: 0.9993\n",
      "Epoch 266/1000 - Val Loss: 0.2733, Val Acc: 0.9123, Val F1: 0.9123, Val Prec: 0.9123, Val Recall: 0.9123\n",
      "\n",
      "Epoch 267/1000 - Train Loss: 0.0429, Train Acc: 0.9996, Train F1: 0.9996, Train Prec: 0.9996, Train Recall: 0.9996\n",
      "Epoch 267/1000 - Val Loss: 0.2707, Val Acc: 0.9130, Val F1: 0.9130, Val Prec: 0.9130, Val Recall: 0.9130\n",
      "\n",
      "Epoch 268/1000 - Train Loss: 0.0395, Train Acc: 0.9997, Train F1: 0.9997, Train Prec: 0.9997, Train Recall: 0.9997\n",
      "Epoch 268/1000 - Val Loss: 0.2665, Val Acc: 0.9123, Val F1: 0.9123, Val Prec: 0.9123, Val Recall: 0.9123\n",
      "\n",
      "Epoch 269/1000 - Train Loss: 0.0395, Train Acc: 0.9999, Train F1: 0.9999, Train Prec: 0.9999, Train Recall: 0.9999\n",
      "Epoch 269/1000 - Val Loss: 0.2732, Val Acc: 0.9103, Val F1: 0.9103, Val Prec: 0.9103, Val Recall: 0.9103\n",
      "\n",
      "Epoch 270/1000 - Train Loss: 0.0405, Train Acc: 0.9997, Train F1: 0.9997, Train Prec: 0.9997, Train Recall: 0.9997\n",
      "Epoch 270/1000 - Val Loss: 0.2863, Val Acc: 0.9103, Val F1: 0.9103, Val Prec: 0.9103, Val Recall: 0.9103\n",
      "\n",
      "Epoch 271/1000 - Train Loss: 0.0423, Train Acc: 0.9997, Train F1: 0.9997, Train Prec: 0.9997, Train Recall: 0.9997\n",
      "Epoch 271/1000 - Val Loss: 0.2700, Val Acc: 0.9083, Val F1: 0.9083, Val Prec: 0.9083, Val Recall: 0.9083\n",
      "\n",
      "Epoch 272/1000 - Train Loss: 0.0411, Train Acc: 0.9999, Train F1: 0.9999, Train Prec: 0.9999, Train Recall: 0.9999\n",
      "Epoch 272/1000 - Val Loss: 0.2846, Val Acc: 0.9120, Val F1: 0.9120, Val Prec: 0.9120, Val Recall: 0.9120\n",
      "\n",
      "Epoch 273/1000 - Train Loss: 0.0389, Train Acc: 0.9999, Train F1: 0.9999, Train Prec: 0.9999, Train Recall: 0.9999\n",
      "Epoch 273/1000 - Val Loss: 0.2750, Val Acc: 0.9113, Val F1: 0.9113, Val Prec: 0.9113, Val Recall: 0.9113\n",
      "\n",
      "Epoch 274/1000 - Train Loss: 0.0398, Train Acc: 0.9999, Train F1: 0.9999, Train Prec: 0.9999, Train Recall: 0.9999\n",
      "Epoch 274/1000 - Val Loss: 0.2693, Val Acc: 0.9113, Val F1: 0.9113, Val Prec: 0.9113, Val Recall: 0.9113\n",
      "\n",
      "Epoch 275/1000 - Train Loss: 0.0389, Train Acc: 0.9994, Train F1: 0.9994, Train Prec: 0.9994, Train Recall: 0.9994\n",
      "Epoch 275/1000 - Val Loss: 0.2632, Val Acc: 0.9123, Val F1: 0.9123, Val Prec: 0.9123, Val Recall: 0.9123\n",
      "\n",
      "Epoch 276/1000 - Train Loss: 0.0387, Train Acc: 1.0000, Train F1: 1.0000, Train Prec: 1.0000, Train Recall: 1.0000\n",
      "Epoch 276/1000 - Val Loss: 0.2754, Val Acc: 0.9130, Val F1: 0.9130, Val Prec: 0.9130, Val Recall: 0.9130\n",
      "\n",
      "Epoch 277/1000 - Train Loss: 0.0377, Train Acc: 0.9999, Train F1: 0.9999, Train Prec: 0.9999, Train Recall: 0.9999\n",
      "Epoch 277/1000 - Val Loss: 0.2857, Val Acc: 0.9140, Val F1: 0.9140, Val Prec: 0.9140, Val Recall: 0.9140\n",
      "\n",
      "Epoch 278/1000 - Train Loss: 0.0394, Train Acc: 0.9997, Train F1: 0.9997, Train Prec: 0.9997, Train Recall: 0.9997\n",
      "Epoch 278/1000 - Val Loss: 0.2667, Val Acc: 0.9120, Val F1: 0.9120, Val Prec: 0.9120, Val Recall: 0.9120\n",
      "\n",
      "Epoch 279/1000 - Train Loss: 0.0393, Train Acc: 0.9997, Train F1: 0.9997, Train Prec: 0.9997, Train Recall: 0.9997\n",
      "Epoch 279/1000 - Val Loss: 0.2676, Val Acc: 0.9130, Val F1: 0.9130, Val Prec: 0.9130, Val Recall: 0.9130\n",
      "\n",
      "Epoch 280/1000 - Train Loss: 0.0385, Train Acc: 1.0000, Train F1: 1.0000, Train Prec: 1.0000, Train Recall: 1.0000\n",
      "Epoch 280/1000 - Val Loss: 0.2688, Val Acc: 0.9100, Val F1: 0.9100, Val Prec: 0.9100, Val Recall: 0.9100\n",
      "\n",
      "Epoch 281/1000 - Train Loss: 0.0386, Train Acc: 0.9997, Train F1: 0.9997, Train Prec: 0.9997, Train Recall: 0.9997\n",
      "Epoch 281/1000 - Val Loss: 0.2696, Val Acc: 0.9090, Val F1: 0.9090, Val Prec: 0.9090, Val Recall: 0.9090\n",
      "\n",
      "Epoch 282/1000 - Train Loss: 0.0362, Train Acc: 0.9997, Train F1: 0.9997, Train Prec: 0.9997, Train Recall: 0.9997\n",
      "Epoch 282/1000 - Val Loss: 0.2790, Val Acc: 0.9090, Val F1: 0.9090, Val Prec: 0.9090, Val Recall: 0.9090\n",
      "\n",
      "Epoch 283/1000 - Train Loss: 0.0385, Train Acc: 0.9994, Train F1: 0.9994, Train Prec: 0.9994, Train Recall: 0.9994\n",
      "Epoch 283/1000 - Val Loss: 0.2688, Val Acc: 0.9100, Val F1: 0.9100, Val Prec: 0.9100, Val Recall: 0.9100\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_805/1035547707.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_and_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensemble_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_805/3130611951.py\u001b[0m in \u001b[0;36mtrain_and_validate\u001b[0;34m(model, train_loader, test_loader, epochs)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_805/1361192161.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Average the outputs from different models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mavg_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_805/1361192161.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Average the outputs from different models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mavg_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_805/1361192161.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Convolutional layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.8/site-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         return F.max_pool1d(input, self.kernel_size, self.stride,\n\u001b[0m\u001b[1;32m     89\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                             self.return_indices)\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.8/site-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool1d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_and_validate(ensemble_model, train_loader, test_loader, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb29725-6652-4d22-aaeb-92dfe9e68d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
